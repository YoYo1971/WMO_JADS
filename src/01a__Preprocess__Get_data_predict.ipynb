{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess - Get data predict --> CHANGES NEEDED LATER\n",
    "This notebook is used to collect data for predicting purposes. The data in this notebook will collect data from different sources. The goal is a X-dataset in parquet format, with:\n",
    "- A number of variables that are used to predict the number of WMO clients. \n",
    "- Index contains a region and time interval\n",
    "- Filename contains a datetime suffix\n",
    "\n",
    "## Content\n",
    "* **Imports**: Imports of needed Python packages\n",
    "* **Settings**: Hard coded variables needed to collect data like sources, tablenames, columnnames, etc. \n",
    "* **Funtions**: Resuable functions\n",
    "* **Load data from sources**: Seperate paragraph for each source\n",
    "    * CBS: WIJK_TABLES\n",
    "* **Combine multiple sources**: Combining all data to one table\n",
    "* **Extend and subset right timewindow**: Code to extend some columns to ensure that all\n",
    "* **Write result**: Writing result to '../data'\n",
    "* **Appendix**: Usefull code to preserve\n",
    "    * Code examples to get a subset of the DataFrame based on multiindex\n",
    "    * Code to get current versions of loaded packages\n",
    "\n",
    "## Requirements\n",
    "The packages to be installed (besides standard Python packages) are:\n",
    "* pandas >=1.1.5\n",
    "* cbsodata >=1.3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cbsodata\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the CBS Statline database\n",
    "CBS_OPEN_URL = 'opendata.cbs.nl'\n",
    "# CBS tables with information of the WMO clients\n",
    "WMO_TABLES = {'2020': '84907NED',\n",
    "            '2019': '84664NED',\n",
    "            '2018': '84421NED',\n",
    "            '2017': '83818NED',\n",
    "            '2016': '83620NED',\n",
    "            '2015': '83267NED'}\n",
    "# CBS tables with the information of key figures for a neighbourhood\n",
    "WIJK_TABLES = {'2020': '84799NED', \n",
    "               '2019': '84583NED', \n",
    "               '2018': '84286NED', \n",
    "               '2017': '83765NED', \n",
    "               '2016': '83487NED', \n",
    "               '2015': '83220NED'} \n",
    "# Dictionary with columns that need to be renamed to avoid duplicates for neighbourhood data\n",
    "DOUBLETROUBLECOLNAMES_WIJK = {'GemiddeldElektriciteitsverbruikTotaal_47': 'GemiddeldElektriciteitsverbruikTotaal_47',\n",
    "                             'Appartement_48': 'GemElectriciteitsverbruikAppartement_48',\n",
    "                             'Tussenwoning_49': 'GemElectriciteitsverbruikTussenwoning_49',\n",
    "                             'Hoekwoning_50': 'GemElectriciteitsverbruikHoekwoning_50',\n",
    "                             'TweeOnderEenKapWoning_51': 'GemElectriciteitsverbruikTweeOnderEenKapWoning_51',\n",
    "                             'VrijstaandeWoning_52': 'GemElectriciteitsverbruikVrijstaandeWoning_52',\n",
    "                             'Huurwoning_53': 'GemElectriciteitsverbruikHuurwoning_53',\n",
    "                             'EigenWoning_54': 'GemElectriciteitsverbruikEigenWoning_54',\n",
    "                              'Koopwoning_54' : 'GemElectriciteitsverbruikEigenWoning_54',\n",
    "                             'GemiddeldAardgasverbruikTotaal_55': 'GemiddeldAardgasverbruikTotaal_55',\n",
    "                             'Appartement_56': 'GemGasverbruikAppartement_56',\n",
    "                             'Tussenwoning_57': 'GemGasverbruikTussenwoning_57',\n",
    "                             'Hoekwoning_58': 'GemGasverbruikHoekwoning_58',\n",
    "                             'TweeOnderEenKapWoning_59': 'GemGasverbruikTweeOnderEenKapWoning_59',\n",
    "                             'VrijstaandeWoning_60': 'GemGasverbruikVrijstaandeWoning_60',\n",
    "                             'Huurwoning_61': 'GemGasverbruikHuurwoning_61',\n",
    "                             'EigenWoning_62': 'GemGasverbruikEigenWoning_62',\n",
    "                              'Koopwoning_62': 'GemGasverbruikEigenWoning_62',\n",
    "                             'PercentageWoningenMetStadsverwarming_63': 'PercentageWoningenMetStadsverwarming_63'}\n",
    "\n",
    "# TO DO: \n",
    "# * ADD list with columns to keep for model! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_combine_cbs_tables(dict_tables, double_trouble_colnames=None, url='opendata.cbs.nl'):\n",
    "    \"\"\"\n",
    "    Method to get multiple simular tables in the CBS database.\n",
    "    \n",
    "    :params dict(str: str) tables: Dictionary with as key the period and as value the table name\n",
    "    :params dict(str: str) double_trouble_colnames: Dictionary with columnnames that will cause trouble if the suffix is deleted\n",
    "    :params str url: URL of the catalog of the CBS databases, i.e.: 'opendata.cbs.nl'\n",
    "    \n",
    "    return: pd.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Number of tables to collect: {len(dict_tables)}\")\n",
    "    \n",
    "    df= pd.DataFrame()\n",
    "    for interval, table in dict_tables.items():\n",
    "        print(f\"Pythonic iteration {interval} for table {table}\")\n",
    "        try:\n",
    "            df_sub = pd.DataFrame(cbsodata.get_data(table, catalog_url=url))\n",
    "            if double_trouble_colnames:\n",
    "                df_sub = df_sub.rename(columns=double_trouble_colnames)\n",
    "            cols_wijk_stripped = [i.rstrip('0123456789').replace(\"_\", \"\").lower() for i in list(df_sub.columns)]\n",
    "            dict_wijk_cols_renamed = {key: value for key, value in zip(iter(df_sub.columns), iter(cols_wijk_stripped))}\n",
    "            df_sub = df_sub.rename(columns=dict_wijk_cols_renamed)\n",
    "            df_sub['interval'] = interval\n",
    "            # print(list(df_sub.columns))\n",
    "        except Exception:\n",
    "            df_sub = pd.DataFrame()\n",
    "            pass\n",
    "        df = pd.concat([df, df_sub])\n",
    "        # print(list(df.columns))\n",
    "    return df\n",
    "\n",
    "def rename_and_subset_cols(df, dict_rename, list_cols, include=True):\n",
    "    \"\"\"\n",
    "    Method to rename and subset certain columns from a DataFrame. \n",
    "    \n",
    "    :params pd.DataFrame df: DataFrame with several columns\n",
    "    :params dict(str:str) dict_rename: Dictionary with a dictionary where the keys are the original columnnames\n",
    "                                       and the values are the new column names\n",
    "    :params list(str) list_cols: List of columns to keep/drop\n",
    "    :params bool include: Boolean value to indicate if the columns from list_cols should be kept or dropped. Default 'true' to keep.\n",
    "    \n",
    "    return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.rename(columns=dict_rename)\n",
    "    if include:\n",
    "        df = df[list_cols]\n",
    "    else:\n",
    "        df = df.drop(list_cols, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def downcast_variables_dataframe(df):\n",
    "    \"\"\"\n",
    "    Method to downcast the variables in a DataFrame\n",
    "    \n",
    "    :params pd.DataFrame: df: DataFrame to downcast\n",
    "    \n",
    "    return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    df_downy = df.copy()\n",
    "    # Downcast dataset\n",
    "    df_downy[df_downy.select_dtypes(include='object').columns] = df_downy.select_dtypes(include='object').astype('category')\n",
    "\n",
    "    for old, new in [('integer', 'unsigned'), ('float', 'float')]:\n",
    "        for col in df.select_dtypes(include=old).columns:\n",
    "            df_downy.loc[:,col] = pd.to_numeric(df_downy.loc[:,col], downcast=new)\n",
    "    return df_downy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBS: WIJK_TABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tables to collect: 6\n",
      "Pythonic iteration 2020 for table 84799NED\n",
      "Pythonic iteration 2019 for table 84583NED\n",
      "Pythonic iteration 2018 for table 84286NED\n",
      "Pythonic iteration 2017 for table 83765NED\n",
      "Pythonic iteration 2016 for table 83487NED\n",
      "Pythonic iteration 2015 for table 83220NED\n",
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get Wijkdata\n",
    "df_wijk = get_and_combine_cbs_tables(dict_tables=WIJK_TABLES, double_trouble_colnames = DOUBLETROUBLECOLNAMES_WIJK, url=CBS_OPEN_URL)\n",
    "DICT_WIJK_COLS_RENAMED = {'codering':'codering_regio', \n",
    "                          'interval':'perioden'}\n",
    "df_wijk_sub = rename_and_subset_cols(df=df_wijk, \n",
    "                                     dict_rename=DICT_WIJK_COLS_RENAMED, \n",
    "                                     list_cols=['id', 'wijkenenbuurten', 'soortregio', 'indelingswijzigingwijkenenbuurten'], \n",
    "                                     include=False)\n",
    "df_wijk_sub['codering_regio'] = df_wijk_sub['codering_regio'].str.strip()\n",
    "df_wijk_sub['gemeentenaam'] = df_wijk_sub['gemeentenaam'].str.strip()\n",
    "df_wijk_total = df_wijk_sub[df_wijk_sub.codering_regio.str.startswith('WK', na=False)]\n",
    "df_wijk_total = downcast_variables_dataframe(df_wijk_total)\n",
    "df_wijk_total = df_wijk_total.set_index(['codering_regio', 'perioden'])\n",
    "df_wijk_total.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source: Type of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible other source (to be added later):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine multiple sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_dataset_WMO = pd.merge(df_wmo_total, df_wijk_total, how='inner', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend and subset right timewindow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dataset_WMO.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_dataset_WMO.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "\n",
    "# df_dataset_WMO.to_parquet(f'../data/df_get_for_predict_WMO_{suffix_datetime}.parquet.gzip',\n",
    "#               compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to get current versions of loaded packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(f'{m.__name__} {m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ames-env]",
   "language": "python",
   "name": "conda-env-ames-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
