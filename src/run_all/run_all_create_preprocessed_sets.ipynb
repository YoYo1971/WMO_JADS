{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Custom functions\n",
    "import src.settings as settings\n",
    "import src.mapper_cols as mapper_cols\n",
    "from src.run_all.main_get_data import get_data\n",
    "from src.run_all.main_preprocess import preprocess_data\n",
    "from src.utilities.utilities import get_latest_file\n",
    "\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data\n",
    "This step will load and combine several tables from CBS statline. \n",
    "\n",
    "Note: This step takes a number of minutes and without changes to the settings will give the same result. Therefor this code is commented out and the original dataset is loaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# ## CREATE NEW DATASET\n",
    "# df_get_data_WMO= get_data(save=True)\n",
    "\n",
    "# ## HARDCODED\n",
    "datapath = '../../data/'\n",
    "filename = 'df_get_data_WMO_WIJK_HUISHOUDENS_BEVOLKING_HEFFING_202104040949.parquet.gzip'\n",
    "df_get_data_WMO = pd.read_parquet(datapath + filename)\n",
    "\n",
    "# ## SELECT LAST FILE\n",
    "# datapath = '../../data/'\n",
    "# df = get_latest_file(filename_str_contains='df_WMO_', datapath=datapath, filetype='parquet')\n",
    "\n",
    "print(f\"The shape of the dataframe from step 'Get Data': {df_get_data_WMO.shape}\")\n",
    "df_get_data_WMO.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess\n",
    "This step will transform (select columns, impute, scale) the dataframe to be used in train/predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsets = {'All': [mapper_cols.DICT_WMO_RELATIVELY_COLS_ALL, \n",
    "                          mapper_cols.LIST_WMO_GET_DATA_ALL, \n",
    "                          None],\n",
    "            'No_Relative': [{}, \n",
    "                          mapper_cols.LIST_WMO_GET_DATA_ALL, \n",
    "                          None],\n",
    "            'Boerenverstand_Maikel': [mapper_cols.DICT_WMO_RELATIVELY_COLS_BOERENVERSTAND_MAIKEL, \n",
    "                                      mapper_cols.LIST_WMO_GET_DATA_BOERENVERSTAND_MAIKEL, \n",
    "                                      mapper_cols.LIST_COLUMNSELECTOR_2_BOERENVERSTAND_MAIKEL],\n",
    "           'Minimum_Maikel': [mapper_cols.DICT_WMO_RELATIVELY_COLS_BOERENVERSTAND_MAIKEL, \n",
    "                              mapper_cols.LIST_WMO_GET_DATA_BOERENVERSTAND_MAIKEL,\n",
    "                             ['codering_regio', 'interval',\n",
    "                              'aantalinwoners','gescheiden','verweduwd','alleenstaande_mannen',\n",
    "                              'alleenstaande_vrouwen','poparbeidsongeschiktheidtotaal',\n",
    "                              'popbevolkingsdichtheid','popk65tot80jaarrelatieveleeftijdsgroep',\n",
    "                              'popk80jaarofouderrelatieveleeftijdsgroep']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in testsets.items():\n",
    "    print(f\"Testset {key} will be created\")\n",
    "    # Set the parameters\n",
    "    settings.preprocess['DICT_RELATIVELY_COLS'] = value[0]\n",
    "    settings.preprocess['LIST_CUSTOMSCALER_COLS'] = value[1]\n",
    "    settings.preprocess['LIST_COLUMNSELECTOR_COLS_2'] = value[2]\n",
    "    # Create set\n",
    "    df_preprocessed = preprocess_data(df=df_get_data_WMO, save_all=True, personal_note=key)\n",
    "    print(f\"The shape of the dataframe from step 'Preprocess': {df_preprocessed.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "## Code examples to get a subset of the DataFrame based on multiindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Subset on columnvalue:\n",
    "# df[df['gemeentenaam']=='Nijmegen']\n",
    "\n",
    "# # One row / record\n",
    "# df.loc[('WK026801', '2019')]\n",
    "\n",
    "# # Multiple rows / records based on combination of the multiindex\n",
    "# df.loc[[('WK026801', '2018'), ('WK026802', '2018')]]\n",
    "\n",
    "# # Multiple rows / records for one column (works only for series)\n",
    "# df['codering_regio'].loc[(['WK026801', 'WK026802'], ['2018', '2019'])]\n",
    "\n",
    "# # Multiple rows based on both indexes:\n",
    "# df.loc(axis=0)[['WK026801', 'WK026802'], ['2018', '2019']]\n",
    "\n",
    "# # Subset with IndexSlice\n",
    "# idx = pd.IndexSlice\n",
    "# # Subset on one of the multiindex and select a column\n",
    "# df.loc[idx[:, ['2018', '2019']], idx[\"codering_regio\"]]\n",
    "# # Subset on one of the multiindex and select all columns\n",
    "# df.loc[idx['WK026801', :], idx[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df['gemeentenaam']=='Nijmegen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to get current versions of loaded packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('\\n'.join(f'{m.__name__} {m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a huge dictionary with all possible columns to scale with RelativeColumnScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a huge dictionary with all possible columns to scale with RelativeColumnScaler\n",
    "# dict_combined = {}\n",
    "# dicts = [mapper_cols.DICT_RELATIVELY_COL_WIJK,\n",
    "#          mapper_cols.DICT_RELATIVELY_COL_HUISHOUDEN,\n",
    "#         mapper_cols.DICT_RELATIVELY_COL_BEVOLKING,\n",
    "#         mapper_cols.DICT_RELATIVELY_COL_HEFFING]\n",
    "\n",
    "# for D in dicts:\n",
    "#     for key, value in D.items():\n",
    "#         if key in dict_combined.keys():\n",
    "#             value_dict_combined = dict_combined[key]\n",
    "#             new_value = list(set(value_dict_combined+value))\n",
    "#             dict_combined[key] = new_value\n",
    "#         else:\n",
    "#             dict_combined[key] = value\n",
    "# dict_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jads-env] *",
   "language": "python",
   "name": "conda-env-jads-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
