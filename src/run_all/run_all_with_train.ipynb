{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from run_all.main_preprocess import load_data, add_features\n",
    "from utilities.utilities import get_latest_file\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load original sources and combine to one DataFrame\n",
    "df_dataset_WMO = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Feature engineering to get more features\n",
    "df_dataset_WMO_with_features = add_features(df_dataset_WMO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Write temporary result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "\n",
    "# df_dataset_WMO_with_features.to_parquet(f'../../data/df_preprocess_WMO_{suffix_datetime}.parquet.gzip',\n",
    "#               compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Load previous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Continue with loaded data from preprocess\n",
    "#df = df_dataset_WMO_with_features.copy()\n",
    "\n",
    "# ## HARDCODED\n",
    "# datapath = '../../data/'\n",
    "# input_filename = 'df_preprocess_WMO_202103211137.parquet.gzip'\n",
    "# df = pd.read_parquet(datapath + input_filename)\n",
    "\n",
    "# ## SELECT LAST FILE\n",
    "datapath = '../../data/'\n",
    "df = get_latest_file(filename_str_contains='df_preprocess_', datapath=datapath, filetype='parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zorgen voor de juiste modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV, cross_validate, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, LassoCV, ElasticNet, BayesianRidge\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "from ColumnSelector import ColumnSelector\n",
    "\n",
    "# instellingen voor panda weergave aanpassen\n",
    "pd.set_option('display.max_rows', 500) # alle rijen tonen\n",
    "pd.set_option('display.max_columns', 500) # alle kolommen tonen\n",
    "pd.set_option('display.width', 1000) # kolombreedte\n",
    "pd.set_option(\"display.precision\", 2)     # precisie van de kolommen aanpassen\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) # floats output tot 3 decimalen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframe parameters\n",
    "# locatie van dataset \n",
    "DF_LOCATION = 'C:/_NoBackup/Git/__JADS/WMO_execute_group_project/data/df_dataset_WMO.parquet.gzip'\n",
    "# Location all data\n",
    "datapath = '../../data/'\n",
    "# manier van laden dataset. Bijvoorbeeld read_parquet of read_csv\n",
    "DF_READ = pd.read_parquet\n",
    "\n",
    "## X & Y parameters\n",
    "# de kolommen die uit de X dataset moeten worden gehaald. Dat is in ieder geval de y en eventueel nog meer kolommen.\n",
    "# X_DROP_VALUES = ['wmoclienten', 'eenpersoonshuishoudens', 'huishoudenszonderkinderen', 'huishoudensmetkinderen']\n",
    "X_DROP_VALUES = ['wmoclienten', 'percentagewmoclienten','wmoclientenper1000inwoners','perioden']\n",
    "# de kolom die wordt gebruikt als y value\n",
    "Y_VALUE = ['wmoclientenper1000inwoners']\n",
    "# test size voor de train/test split\n",
    "TEST_SIZE = 0.3\n",
    "# random state voor de train/test split. Bijvoorbeeld random_state = 42 als vaste seed voor reproduceerbaarheid\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "## Pipeline parameters\n",
    "# strategy en waarde om te vullen bij lege categorische kolommen\n",
    "NAN_VALUES_CAT_STRATEGY = 'constant'\n",
    "NAN_VALUES_CAT_VALUES = 'Missing'\n",
    "# waarden om in te vullen bij lege numerieke kolommen. Bijvoorbeeld mean of median\n",
    "NAN_VALUES_NUM_STRATEGY = 'mean'\n",
    "# \n",
    "#COLS_SELECT = ['aantalinwoners', 'mannen', 'vrouwen', 'k0tot15jaar'\n",
    "#               , 'k15tot25jaar', 'k25tot45jaar', 'k45tot65jaar', 'k65jaarofouder', 'gescheiden'\n",
    "#               , 'verweduwd', 'westerstotaal', 'sterftetotaal', 'gemiddeldehuishoudensgrootte'\n",
    "#               , 'gemiddeldewoningwaarde', 'koopwoningen', 'huurwoningentotaal', 'inbezitwoningcorporatie'\n",
    "#               , 'gemiddeldinkomenperinkomensontvanger', 'k40personenmetlaagsteinkomen', 'k20personenmethoogsteinkomen'\n",
    "#               , 'actieven1575jaar', 'k40huishoudensmetlaagsteinkomen', 'k20huishoudensmethoogsteinkomen'\n",
    "#               , 'huishoudensmeteenlaaginkomen', 'personenpersoortuitkeringaow', 'rucultuurrecreatieoverigediensten'\n",
    "#               , 'personenautosperhuishouden', 'matevanstedelijkheid']\n",
    "COLS_SELECT = None\n",
    "\n",
    "## Model parameters\n",
    "\n",
    "# manier van cross validate in de modellen. Bijvoorbeeld 10 of RepeatedKFold(n_splits=30, n_repeats=5, random_state=1)\n",
    "CROSS_VALIDATE = 5\n",
    "# manier van scoren in de modellen\n",
    "MODEL_SCORING = 'neg_mean_squared_error'\n",
    "## Grid Search parameters\n",
    "\n",
    "# parameters die gebruikt worden in de grid search\n",
    "\n",
    "ALPHA = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "NEIGHBORS = [3, 5, 11, 19]\n",
    "NORMALIZE = [True, False]\n",
    "KERNEL = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
    "GAMMA = [0.5, 1, 1.5, 2, 5]\n",
    "N_ESTIMATORS = [50,100,200]\n",
    "C_REGULARIZATION = [0.001, 0.01, 0,1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # functie maken om op basis van de cv scores, het beste RMSE model te selecteren \n",
    "# def get_best_model_rmsle(cv_scores):\n",
    "#     \"\"\"\n",
    "#     Return best (most conservative) model from cross_validate object.\n",
    "    \n",
    "#     Uses np.argmax to find bottomright point == largest RMSE\n",
    "#     \"\"\"\n",
    "#     index = np.argmax(np.sqrt(-cv_scores['train_neg_mean_squared_error']))\n",
    "#     model = cv_scores['estimator'][index]\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
    "#     return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_from_specific_columns (df,columns_to_check):\n",
    "    \"\"\"\n",
    "    Drops all rows with nan values in specific columns in a dataframe\n",
    "    \"\"\"\n",
    "    df.dropna(\n",
    "        axis=0,\n",
    "        how='any',\n",
    "        thresh=None,\n",
    "        subset=columns_to_check,\n",
    "        inplace=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_clf_and_params(best_estimator_clf):\n",
    "    clf_and_params = str(best_estimator_clf)\n",
    "    clf_and_params = clf_and_params.replace(\")\", \"\")\n",
    "    clf_and_params_split = clf_and_params.split(\"(\")\n",
    "    return clf_and_params_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functie maken om op basis van de grid search best estimator, het beste RMSE model te selecteren \n",
    "def rmse_from_gridsearch_best_estimator(grid_search):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from the grid search best estimator\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_from_neg_mean_squared_error(neg_mean_squared_error):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from the neq mean squared error\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(-(neg_mean_squared_error))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Done before start of 'Train' chapter\n",
    "# df = get_latest_file(mypath=datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stappen hieronder mogelijk verplaatsten naar prepare stap, later beoordelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checken of er rijen in het dataframe zitten waarbij de Y_value leeg is. Die rijen worden eruit gehaald.\n",
    "drop_nan_from_specific_columns(df,Y_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X en y aanmaken\n",
    "X = df.drop(X_DROP_VALUES, axis=1)\n",
    "y = df[Y_VALUE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitsen van X en y in train/test. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitsen van X_train in categorische en numerieke kolommen, om apart te kunnen transformeren\n",
    "cat_cols = X_train.select_dtypes(include=['category']).columns\n",
    "num_cols = X_train.select_dtypes(include=['int64','float64','float32','int32']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines (pl) maken voor imputing, scaling en OneHotEncoding per datatype \n",
    "\n",
    "# categorie met waarde die is gegeven aan \"MISSING\" toevoegen\n",
    "for col in cat_cols:\n",
    "    # need to add category for missings, otherwise error with OneHotEncoding (volgens mij ook met alleen imputing)\n",
    "    X_train[col].cat.add_categories(NAN_VALUES_CAT_VALUES, inplace=True)\n",
    "categories = [X_train[col].cat.categories for col in cat_cols]\n",
    "\n",
    "# pipeline voor categorial datatype\n",
    "pl_ppc_cat = make_pipeline(\n",
    "     SimpleImputer(\n",
    "         missing_values = np.nan\n",
    "        ,strategy = NAN_VALUES_CAT_STRATEGY\n",
    "        ,fill_value = NAN_VALUES_CAT_VALUES)\n",
    "    ,OneHotEncoder(categories=categories)\n",
    ")\n",
    "\n",
    "# pipeline voor numeriek datatype\n",
    "pl_ppc_num = make_pipeline(\n",
    "      ColumnSelector(cols=COLS_SELECT)\n",
    "    ,SimpleImputer(\n",
    "         missing_values = np.nan\n",
    "        ,strategy = NAN_VALUES_NUM_STRATEGY)\n",
    "    ,StandardScaler()\n",
    "    #,PCA() # PCA heeft behoorlijk wat (positieve) invloed op de scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines maken om de preprocessing van de imputing te combineren\n",
    "pl_ppc_total = make_column_transformer(\n",
    "     (pl_ppc_cat, cat_cols)\n",
    "    ,(pl_ppc_num, num_cols)\n",
    "    ,remainder = 'drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken om in de grid search te kunnen gebruiken\n",
    "pl_gs_total = Pipeline([('preprocess', pl_ppc_total),\n",
    "                       ('clf', LinearRegression())]) # Placeholder Estimator\n",
    "    \n",
    "# param grid waarin alle classifiers + hyper parameters kunnen worden opgenomen. \n",
    "# hier classifiers (modellen) + parameters toevoegen\n",
    "param_grid_total = [{'clf': [LinearRegression()], \n",
    "                     'clf__normalize': NORMALIZE,},\n",
    "                    \n",
    "                    {'clf': [Ridge()],  \n",
    "                     'clf__alpha': ALPHA},\n",
    "                    \n",
    "                    {'clf': [Lasso()], \n",
    "                     'clf__alpha': ALPHA},\n",
    "                   \n",
    "                 #   {'clf': [KNeighborsRegressor()],  \n",
    "                 #    'clf__n_neighbors': NEIGHBORS},\n",
    "                     \n",
    "                 #  {'clf': [SVR()], \n",
    "                 #   'clf__kernel': KERNEL,\n",
    "                 #   'clf__C': C_REGULARIZATION},\n",
    "                    \n",
    "                   {'clf': [XGBRegressor()],  \n",
    "                    'clf__gamma': GAMMA,\n",
    "                    'clf__n_estimators': N_ESTIMATORS},                   \n",
    "                   ]\n",
    "    \n",
    "# grid search aanmaken\n",
    "grid_search_total = GridSearchCV(pl_gs_total, param_grid_total, cv=CROSS_VALIDATE,\n",
    "                           scoring=MODEL_SCORING,\n",
    "                           return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 15s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('preprocess',\n",
       "                                        ColumnTransformer(transformers=[('pipeline-1',\n",
       "                                                                         Pipeline(steps=[('simpleimputer',\n",
       "                                                                                          SimpleImputer(fill_value='Missing',\n",
       "                                                                                                        strategy='constant')),\n",
       "                                                                                         ('onehotencoder',\n",
       "                                                                                          OneHotEncoder(categories=[]))]),\n",
       "                                                                         Index([], dtype='object')),\n",
       "                                                                        ('pipeline-2',\n",
       "                                                                         Pipeline(steps=[('columnselector',\n",
       "                                                                                          ColumnSelector()),\n",
       "                                                                                         ('simpleimputer...\n",
       "                                               missing=nan,\n",
       "                                               monotone_constraints=None,\n",
       "                                               n_estimators=100, n_jobs=None,\n",
       "                                               num_parallel_tree=None,\n",
       "                                               random_state=None,\n",
       "                                               reg_alpha=None, reg_lambda=None,\n",
       "                                               scale_pos_weight=None,\n",
       "                                               subsample=None, tree_method=None,\n",
       "                                               validate_parameters=None,\n",
       "                                               verbosity=None)],\n",
       "                          'clf__gamma': [0.5, 1, 1.5, 2, 5],\n",
       "                          'clf__n_estimators': [50, 100, 200]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "#grid search uitvoeren\n",
    "grid_search_total.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_grid_search = pd.DataFrame(grid_search_total.cv_results_)\n",
    "#pd_grid_search = pd_grid_search.sort_values('rank_test_score', ascending=True)\n",
    "#pd_grid_search.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search_total.cv_results_['params'][grid_search_total.best_index_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Het model met de beste train score is:\n",
      "Ridge(alpha=1)\n",
      "Dit model heeft een train score RMSE van 0.0008757480164296834\n",
      "Dit model heeft een test score RMSE van  0.0008746195384506971\n"
     ]
    }
   ],
   "source": [
    "# de best estimator uit de grid search halen (beste train score)\n",
    "print(f\"Het model met de beste train score is:\\n{grid_search_total.best_estimator_['clf']}\")\n",
    "# de RMSE berekenen voor de best estimator\n",
    "print(f\"Dit model heeft een train score RMSE van {rmse_from_neg_mean_squared_error(grid_search_total.best_score_)}\") \n",
    "print(f\"Dit model heeft een test score RMSE van  {rsme_from_gridsearch_best_estimator(grid_search_total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best model and best model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "output_filename = f'../../data/best_model_{suffix_datetime}.pickle'\n",
    "pickle.dump(grid_search_total.best_estimator_, open(output_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra regel om tijdelijk een dummy bij input_filename te krijgen\n",
    "input_filename = 'Hier komt uiteindelijk de input_filename_locatie'\n",
    "# dictionary maken van alle properties die van het beste model moeten worden opgeslagen\n",
    "best_model_properties_dict = {\"Model\": [split_clf_and_params(grid_search_total.best_estimator_['clf'])[0]],\n",
    "                        \"Gridsearch_Params\": [split_clf_and_params(grid_search_total.best_estimator_['clf'])[1]],\n",
    "                        \"Train_RMSE\": [rmse_from_neg_mean_squared_error(grid_search_total.best_score_)],\n",
    "                        \"Test_RMSE\": [rmse_from_gridsearch_best_estimator(grid_search_total)],\n",
    "                        \"Number_of_features\": [len(X.columns)],\n",
    "                        \"Y_value\": Y_VALUE,\n",
    "                        \"Input_filename\": [input_filename],\n",
    "                        \"Output_filename\": [output_filename],\n",
    "                                     }\n",
    "best_model_properties = pd.DataFrame(best_model_properties_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Model': ['Ridge'],\n",
       " 'Gridsearch_Params': ['alpha=1'],\n",
       " 'Train_RMSE': [0.0008757480164296834],\n",
       " 'Test_RMSE': [0.0008746195384506971],\n",
       " 'Number_of_features': [140],\n",
       " 'Y_value': ['wmoclientenper1000inwoners'],\n",
       " 'Input_filename': ['Hier komt uiteindelijk de input_filename_locatie'],\n",
       " 'Output_filename': ['../../data/best_model_202104021328.pickle']}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_properties_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Gridsearch_Params</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Test_RMSE</th>\n",
       "      <th>Number_of_features</th>\n",
       "      <th>Y_value</th>\n",
       "      <th>Input_filename</th>\n",
       "      <th>Output_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>alpha=1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>140</td>\n",
       "      <td>wmoclientenper1000inwoners</td>\n",
       "      <td>Hier komt uiteindelijk de input_filename_locatie</td>\n",
       "      <td>../../data/best_model_202104021328.pickle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Gridsearch_Params  Train_RMSE  Test_RMSE  Number_of_features                     Y_value                                    Input_filename                            Output_filename\n",
       "0  Ridge           alpha=1       0.001      0.001                 140  wmoclientenper1000inwoners  Hier komt uiteindelijk de input_filename_locatie  ../../data/best_model_202104021328.pickle"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   0.001\n",
       "Name: Train_RMSE, dtype: float64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_properties['Train_RMSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opslaan van beste model naar csv\n",
    "best_model_properties.to_csv(f'../../data/best_model_properties{suffix_datetime}.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickle file inladen voor predict\n",
    "# loaded_model = get_latest_file(output_filename_str_contains='best_model_', datapath=datapath, filetype='pickle')\n",
    "# # hoe moet ik deze score interpreteren?\n",
    "# result = loaded_model.score(X_test, y_test)\n",
    "# print(result)\n",
    "# loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regel om te testen of opgeslagen pickle file overeen komt met model\n",
    "#grid_search_total.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dit is het beste model uit de grid search\n",
    "#grid_search_total.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUDE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_gs_dict = {'Linear Regression': 'grid_search_lr',\n",
    "#                   'Ridge Regression': 'grid_search_rr',\n",
    "#                   'Lasso': 'grid_search_lasso',\n",
    "#                   'K Nearest Neighbor': 'grid_search_knn',\n",
    "#                   'Support Vector Machines': 'grid_search_svm',\n",
    "#                   'XGBoost': 'grid_search_xgb',\n",
    "#                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # nog aan te passen\n",
    "# def append_gridsearch_scores(models_gs_dict):\n",
    "#     for key,item in models_gs_dict.items():\n",
    "#         gridsearch_rsme_scores.append((key,  rsme_from_gridsearch_best_estimator(item)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toevoegen van de beste scores, per model, aan een lijst\n",
    "#gridsearch_rsme_scores = []\n",
    "#gridsearch_rsme_scores.append(('Linear Regression',  rsme_from_gridsearch_best_estimator(grid_search_lr)))\n",
    "#gridsearch_rsme_scores.append(('Ridge Regression',  rsme_from_gridsearch_best_estimator(grid_search_rr)))\n",
    "#gridsearch_rsme_scores.append(('Lasso', rsme_from_gridsearch_best_estimator(grid_search_lasso)))\n",
    "#gridsearch_rsme_scores.append(('K Nearest Neighbor', rsme_from_gridsearch_best_estimator(grid_search_knn)))\n",
    "#gridsearch_rsme_scores.append(('Support Vector Machines', rsme_from_gridsearch_best_estimator(grid_search_svm)))\n",
    "#gridsearch_rsme_scores.append(('XGBoost', rsme_from_gridsearch_best_estimator(grid_search_xgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # maken van een dataframe met daarin de gesorteerde scores per model\n",
    "# #gridsearch_rsme_scores = []\n",
    "# #append_gridsearch_scores(models_gs_dict)\n",
    "# gridsearch_rsme_scores = pd.DataFrame(gridsearch_rsme_scores)\n",
    "# gridsearch_rsme_scores.columns = ['Algorithm', 'RMSE'] \n",
    "# gridsearch_rsme_scores['RMSE'] = gridsearch_rsme_scores['RMSE'].map('{:,.10f}'.format)\n",
    "# gridsearch_rsme_scores = gridsearch_rsme_scores.sort_values('RMSE', ascending=True)\n",
    "# gridsearch_rsme_scores = gridsearch_rsme_scores.reset_index(drop=True)\n",
    "# gridsearch_rsme_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # and the winner is...\n",
    "# print(f\"Het algoritme met de laagste RMSE is:\\n\\n{gridsearch_rsme_scores.iloc[0,0]}, met een RMSE van {gridsearch_rsme_scores.iloc[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model (deze moet nog aangepast worden naar Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Temporary: select best model (needs function)\n",
    "# BEST_SCORE = lasso_scores\n",
    "# index = np.argmax(np.sqrt(-BEST_SCORE['train_neg_mean_squared_error']))\n",
    "# model = BEST_SCORE['estimator'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "# filename = f'../../data/best_model_{suffix_datetime}.pickle'\n",
    "\n",
    "# pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# joblib.dump(grid.best_estimator_,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test load model (deze moet nog aangepast worden naar Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = get_latest_file(filename_str_contains='best_model_', datapath=datapath, filetype='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = loaded_model.score(X_test, y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra code, nog opschonen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_grid_search = pd.DataFrame(grid_search.cv_results_)\n",
    "#pd_grid_search.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_mse = np.sqrt(mean_squared_error(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "#print(f\"{final_mse:.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train pipelines maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor LinearRegression \n",
    "# pl_lr = make_pipeline(\n",
    "#      pl_ppc_total\n",
    "#     ,LinearRegression()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor RidgeRegression \n",
    "# pl_rr = make_pipeline(\n",
    "#      pl_ppc_total\n",
    "#     ,Ridge()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor Lasso\n",
    "# pl_lasso = make_pipeline(\n",
    "#       pl_ppc_total\n",
    "#      ,Lasso(alpha=0.001)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor KNN\n",
    "# pl_knn = make_pipeline(\n",
    "#       pl_ppc_total\n",
    "#      ,KNeighborsRegressor()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor SVR\n",
    "# pl_svm = make_pipeline(\n",
    "#       pl_ppc_total\n",
    "#      ,SVR()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor XGB\n",
    "# pl_xgb = make_pipeline(\n",
    "#       pl_ppc_total\n",
    "#      ,XGBRegressor()\n",
    "# ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lineair Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scores voor LR berekenen\n",
    "# lr_scores = cross_validate(\n",
    "#     pl_lr, X_train, y_train,\n",
    "#     cv = CROSS_VALIDATE,\n",
    "#     scoring=([MODEL_SCORING]),\n",
    "#     return_train_score=True,\n",
    "#     return_estimator=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rr_scores = cross_validate(\n",
    "#     pl_rr, X_train, y_train,\n",
    "#     cv = CROSS_VALIDATE,\n",
    "#     scoring = ([MODEL_SCORING]),\n",
    "#     return_train_score=True,\n",
    "#     return_estimator=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso_scores = cross_validate(\n",
    "#     pl_lasso, X_train, y_train,\n",
    "#     cv = CROSS_VALIDATE,\n",
    "#     scoring = ([MODEL_SCORING]),\n",
    "#     return_train_score=True,\n",
    "#     return_estimator=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_scores = cross_validate(\n",
    "#     pl_knn, X_train, y_train,\n",
    "#     cv = CROSS_VALIDATE,\n",
    "#     scoring = ([MODEL_SCORING]),\n",
    "#     return_train_score=True,\n",
    "#     return_estimator=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# svm_scores = cross_validate(\n",
    "#     pl_svm, X_train, y_train,\n",
    "#     cv = CROSS_VALIDATE,\n",
    "#     scoring = ([MODEL_SCORING]),\n",
    "#     return_train_score=True,\n",
    "#     return_estimator=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_scores = cross_validate(\n",
    "#     pl_xgb, X_train, y_train,\n",
    "#     cv = CROSS_VALIDATE,\n",
    "#     scoring = ([MODEL_SCORING]),\n",
    "#     return_train_score=True,\n",
    "#     return_estimator=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # toevoegen van de scores van de best estimator, per gridsearch model, aan een lijst\n",
    "# scores = []\n",
    "# scores.append(('Linear Regression',  get_best_model_rmsle(lr_scores)))\n",
    "# scores.append(('Ridge Regression',  get_best_model_rmsle(rr_scores)))\n",
    "# scores.append(('Lasso', get_best_model_rmsle(lasso_scores)))\n",
    "# scores.append(('K Nearest Neighbor', get_best_model_rmsle(knn_scores)))\n",
    "# scores.append(('Support Vector Machines', get_best_model_rmsle(svm_scores)))\n",
    "# scores.append(('XGBoost', get_best_model_rmsle(xgb_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores.append(('Lasso', get_best_model_rmsle(lasso_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # maken van een dataframe met daarin de gesorteerde scores per model\n",
    "# scores = pd.DataFrame(scores)\n",
    "# scores.columns = ['Algorithm', 'RMSE'] \n",
    "# scores['RMSE'] = scores['RMSE'].map('{:,.10f}'.format)\n",
    "# scores = scores.sort_values('RMSE', ascending=True)\n",
    "# scores = scores.reset_index(drop=True)\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # and the winner is...\n",
    "# print(f\"Het algoritme met de laagste RMSE is:\\n\\n{scores.iloc[0,0]}, met een RMSE van {scores.iloc[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Temporary: select best model (needs function)\n",
    "# BEST_SCORE = lasso_scores\n",
    "# index = np.argmax(np.sqrt(-BEST_SCORE['train_neg_mean_squared_error']))\n",
    "# model = BEST_SCORE['estimator'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "# filename = f'../../data/best_model_{suffix_datetime}.pickle'\n",
    "\n",
    "# pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = get_latest_file(filename_str_contains='best_model_', datapath=datapath, filetype='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = loaded_model.score(X_test, y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor Linear Regression\n",
    "# pl_gs_lr = Pipeline(\n",
    "#      [('preprocess', pl_ppc_total),\n",
    "#      ('model_lr',LinearRegression()) \n",
    "#      ]\n",
    "# )\n",
    "\n",
    "# # pipeline maken voor RidgeRegression\n",
    "# pl_gs_rr = Pipeline(\n",
    "#      [('preprocess', pl_ppc_total),\n",
    "#      ('model_rr',Ridge()) \n",
    "#      ]\n",
    "# )\n",
    "\n",
    "# # pipeline maken voor Lasso\n",
    "# pl_gs_lasso = Pipeline(\n",
    "#      [('preprocess', pl_ppc_total),\n",
    "#        ('model_lasso',Lasso()) \n",
    "#      ]\n",
    "# )\n",
    "\n",
    "# # pipeline maken voor KNN\n",
    "# pl_gs_knn = Pipeline(\n",
    "#      [('preprocess', pl_ppc_total),\n",
    "#        ('model_knn', KNeighborsRegressor()) \n",
    "#      ]\n",
    "# )\n",
    "\n",
    "# # pipeline maken voor SVM\n",
    "# pl_gs_svm = Pipeline(\n",
    "#      [('preprocess', pl_ppc_total),\n",
    "#        ('model_svm', SVR()) \n",
    "#      ]\n",
    "# )\n",
    "\n",
    "# # pipeline maken voor XGB\n",
    "# pl_gs_xgb = Pipeline(\n",
    "#      [('preprocess', pl_ppc_total),\n",
    "#        ('model_xgb',XGBRegressor()) \n",
    "#      ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameters Linieare Regression\n",
    "# param_grid_lr = [\n",
    "#     {'model_lr__normalize': NORMALIZE},\n",
    "#     ]\n",
    "\n",
    "# # Parameters RidgeRegression\n",
    "# param_grid_rr = [\n",
    "#      {'model_rr__alpha': ALPHA},  \n",
    "#     ]\n",
    "\n",
    "# # Parameters Lasso\n",
    "# param_grid_lasso = [\n",
    "#      {'model_lasso__alpha': ALPHA},  \n",
    "#     ]\n",
    "\n",
    "# # Parameters KNneighbors\n",
    "# param_grid_knn = [\n",
    "#      {'model_knn__n_neighbors': NEIGHBORS },  \n",
    "#     ]\n",
    "\n",
    "# # Parameters SVM\n",
    "# param_grid_svm = [\n",
    "#      {'model_svm__kernel': KERNEL },  \n",
    "#     ]\n",
    "\n",
    "# # Parameters XGB\n",
    "# param_grid_xgb = [\n",
    "#      {'model_xgb__gamma': GAMMA},  \n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Gridsearch LR \n",
    "# grid_search_lr = GridSearchCV(pl_gs_lr, param_grid_lr, cv=CROSS_VALIDATE,\n",
    "#                            scoring=MODEL_SCORING,\n",
    "#                            return_train_score=True)\n",
    "# grid_search_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Gridsearch RR \n",
    "# grid_search_rr = GridSearchCV(pl_gs_rr, param_grid_rr, cv=CROSS_VALIDATE,\n",
    "#                            scoring=MODEL_SCORING,\n",
    "#                            return_train_score=True)\n",
    "# grid_search_rr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Gridsearch Lasso \n",
    "# grid_search_lasso = GridSearchCV(pl_gs_lasso, param_grid_lasso, cv=CROSS_VALIDATE,\n",
    "#                            scoring=MODEL_SCORING,\n",
    "#                            return_train_score=True)\n",
    "# grid_search_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Gridsearch KNN \n",
    "# grid_search_knn = GridSearchCV(pl_gs_knn, param_grid_knn, cv=CROSS_VALIDATE,\n",
    "#                            scoring=MODEL_SCORING,\n",
    "#                            return_train_score=True)\n",
    "# grid_search_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Gridsearch SVM \n",
    "# grid_search_svm = GridSearchCV(pl_gs_svm, param_grid_svm, cv=CROSS_VALIDATE,\n",
    "#                            scoring=MODEL_SCORING,\n",
    "#                            return_train_score=True)\n",
    "# grid_search_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Gridsearch XGB\n",
    "# grid_search_xgb = GridSearchCV(pl_gs_xgb, param_grid_xgb, cv=CROSS_VALIDATE,\n",
    "#                            scoring=MODEL_SCORING,\n",
    "#                            return_train_score=True)\n",
    "# grid_search_xgb.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
