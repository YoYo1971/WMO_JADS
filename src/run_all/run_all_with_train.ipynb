{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from run_all.main_preprocess import load_data, add_features\n",
    "from utilities.utilities import get_latest_file\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load original sources and combine to one DataFrame\n",
    "df_dataset_WMO = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Feature engineering to get more features\n",
    "df_dataset_WMO_with_features = add_features(df_dataset_WMO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Write temporary result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "\n",
    "# df_dataset_WMO_with_features.to_parquet(f'../../data/df_preprocess_WMO_{suffix_datetime}.parquet.gzip',\n",
    "#               compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Load previous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Continue with loaded data from preprocess\n",
    "#df = df_dataset_WMO_with_features.copy()\n",
    "\n",
    "# ## HARDCODED\n",
    "# datapath = '../../data/'\n",
    "# filename = 'df_preprocess_WMO_202103211137.parquet.gzip'\n",
    "# df = pd.read_parquet(datapath + filename)\n",
    "\n",
    "# ## SELECT LAST FILE\n",
    "datapath = '../../data/'\n",
    "df = get_latest_file(filename_str_contains='df_preprocess_', datapath=datapath, filetype='parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zorgen voor de juiste modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV, cross_validate, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, LassoCV, ElasticNet, BayesianRidge\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "from ColumnSelector import ColumnSelector\n",
    "\n",
    "# instellingen voor panda weergave aanpassen\n",
    "pd.set_option('display.max_rows', 500) # alle rijen tonen\n",
    "pd.set_option('display.max_columns', 500) # alle kolommen tonen\n",
    "pd.set_option('display.width', 1000) # kolombreedte\n",
    "pd.set_option(\"display.precision\", 2)     # precisie van de kolommen aanpassen\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) # floats output tot 3 decimalen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframe parameters\n",
    "# locatie van dataset \n",
    "DF_LOCATION = 'C:/_NoBackup/Git/__JADS/WMO_execute_group_project/data/df_dataset_WMO.parquet.gzip'\n",
    "# Location all data\n",
    "datapath = '../../data/'\n",
    "# manier van laden dataset. Bijvoorbeeld read_parquet of read_csv\n",
    "DF_READ = pd.read_parquet\n",
    "\n",
    "## X & Y parameters\n",
    "# de kolommen die uit de X dataset moeten worden gehaald. Dat is in ieder geval de y en eventueel nog meer kolommen.\n",
    "# X_DROP_VALUES = ['wmoclienten', 'eenpersoonshuishoudens', 'huishoudenszonderkinderen', 'huishoudensmetkinderen']\n",
    "X_DROP_VALUES = ['wmoclienten', 'percentagewmoclienten','wmoclientenper1000inwoners','perioden']\n",
    "# de kolom die wordt gebruikt als y value\n",
    "Y_VALUE = ['wmoclientenper1000inwoners']\n",
    "# test size voor de train/test split\n",
    "TEST_SIZE = 0.3\n",
    "# random state voor de train/test split. Bijvoorbeeld random_state = 42 als vaste seed voor reproduceerbaarheid\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "## Pipeline parameters\n",
    "# strategy en waarde om te vullen bij lege categorische kolommen\n",
    "NAN_VALUES_CAT_STRATEGY = 'constant'\n",
    "NAN_VALUES_CAT_VALUES = 'Missing'\n",
    "# waarden om in te vullen bij lege numerieke kolommen. Bijvoorbeeld mean of median\n",
    "NAN_VALUES_NUM_STRATEGY = 'mean'\n",
    "# \n",
    "#COLS_SELECT = ['aantalinwoners', 'mannen', 'vrouwen', 'k0tot15jaar'\n",
    "#               , 'k15tot25jaar', 'k25tot45jaar', 'k45tot65jaar', 'k65jaarofouder', 'gescheiden'\n",
    "#               , 'verweduwd', 'westerstotaal', 'sterftetotaal', 'gemiddeldehuishoudensgrootte'\n",
    "#               , 'gemiddeldewoningwaarde', 'koopwoningen', 'huurwoningentotaal', 'inbezitwoningcorporatie'\n",
    "#               , 'gemiddeldinkomenperinkomensontvanger', 'k40personenmetlaagsteinkomen', 'k20personenmethoogsteinkomen'\n",
    "#               , 'actieven1575jaar', 'k40huishoudensmetlaagsteinkomen', 'k20huishoudensmethoogsteinkomen'\n",
    "#               , 'huishoudensmeteenlaaginkomen', 'personenpersoortuitkeringaow', 'rucultuurrecreatieoverigediensten'\n",
    "#               , 'personenautosperhuishouden', 'matevanstedelijkheid']\n",
    "COLS_SELECT = None\n",
    "\n",
    "## Model parameters\n",
    "\n",
    "# manier van cross validate in de modellen. Bijvoorbeeld 10 of RepeatedKFold(n_splits=30, n_repeats=5, random_state=1)\n",
    "CROSS_VALIDATE = 5\n",
    "# manier van scoren in de modellen\n",
    "MODEL_SCORING = 'neg_mean_squared_error'\n",
    "## Grid Search parameters\n",
    "\n",
    "# parameters die gebruikt worden in de grid search\n",
    "\n",
    "ALPHA = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "NEIGHBORS = [3, 5, 11, 19]\n",
    "NORMALIZE = [True, False]\n",
    "KERNEL = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
    "GAMMA = [0.5, 1, 1.5, 2, 5]\n",
    "N_ESTIMATORS = [50,100,200]\n",
    "C_REGULARIZATION = [0.001, 0.01, 0,1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # functie maken om op basis van de cv scores, het beste RMSE model te selecteren \n",
    "# def get_best_model_rmsle(cv_scores):\n",
    "#     \"\"\"\n",
    "#     Return best (most conservative) model from cross_validate object.\n",
    "    \n",
    "#     Uses np.argmax to find bottomright point == largest RMSE\n",
    "#     \"\"\"\n",
    "#     index = np.argmax(np.sqrt(-cv_scores['train_neg_mean_squared_error']))\n",
    "#     model = cv_scores['estimator'][index]\n",
    "#     rmse = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
    "#     return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functie maken om op basis van de grid search best estimator, het beste RMSE model te selecteren \n",
    "def rsme_from_gridsearch_best_estimator(grid_search):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from the grid search best estimator\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_from_specific_columns (df,columns_to_check):\n",
    "    \"\"\"\n",
    "    Drops all rows with nan values in specific columns in a dataframe\n",
    "    \"\"\"\n",
    "    df.dropna(\n",
    "        axis=0,\n",
    "        how='any',\n",
    "        thresh=None,\n",
    "        subset=columns_to_check,\n",
    "        inplace=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Done before start of 'Train' chapter\n",
    "# df = get_latest_file(mypath=datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stappen hieronder mogelijk verplaatsten naar prepare stap, later beoordelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_x_y_train_test(df, X_DROP_VALUES, Y_VALUE):\n",
    "#     \"\"\"\n",
    "#     Creates X_train, X_test, y_train, y_test from pandas dataframe. \n",
    "#     Input:\n",
    "#         A dataframe, \n",
    "#         List of X_values to drop\n",
    "#         Y_value\n",
    "#     \"\"\"    \n",
    "#     X = df.drop(X_DROP_VALUES, axis=1)\n",
    "#     y = df[Y_VALUE]\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE, random_state = RANDOM_STATE)\n",
    "#     return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_x_y_train_test(df,X_DROP_VALUES,Y_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_latest_file(filename_str_contains='df_preprocess_', datapath=datapath, filetype='parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checken of er rijen in het dataframe zitten waarbij de Y_value leeg is. Die rijen worden eruit gehaald.\n",
    "drop_nan_from_specific_columns(df,Y_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X en y aanmaken\n",
    "X = df.drop(X_DROP_VALUES, axis=1)\n",
    "y = df[Y_VALUE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitsen van X en y in train/test. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitsen van X_train in categorische en numerieke kolommen, om apart te kunnen transformeren\n",
    "cat_cols = X_train.select_dtypes(include=['category']).columns\n",
    "num_cols = X_train.select_dtypes(include=['int64','float64','float32','int32']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines (pl) maken voor imputing, scaling en OneHotEncoding per datatype \n",
    "\n",
    "# categorie met waarde die is gegeven aan \"MISSING\" toevoegen\n",
    "for col in cat_cols:\n",
    "    # need to add category for missings, otherwise error with OneHotEncoding (volgens mij ook met alleen imputing)\n",
    "    X_train[col].cat.add_categories(NAN_VALUES_CAT_VALUES, inplace=True)\n",
    "categories = [X_train[col].cat.categories for col in cat_cols]\n",
    "\n",
    "# pipeline voor categorial datatype\n",
    "pl_ppc_cat = make_pipeline(\n",
    "     SimpleImputer(\n",
    "         missing_values = np.nan\n",
    "        ,strategy = NAN_VALUES_CAT_STRATEGY\n",
    "        ,fill_value = NAN_VALUES_CAT_VALUES)\n",
    "    ,OneHotEncoder(categories=categories)\n",
    ")\n",
    "\n",
    "# pipeline voor numeriek datatype\n",
    "pl_ppc_num = make_pipeline(\n",
    "      ColumnSelector(cols=COLS_SELECT)\n",
    "    ,SimpleImputer(\n",
    "         missing_values = np.nan\n",
    "        ,strategy = NAN_VALUES_NUM_STRATEGY)\n",
    "    ,StandardScaler()\n",
    "    #,PCA() # PCA heeft behoorlijk wat (positieve) invloed op de scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines maken om de preprocessing van de imputing te combineren\n",
    "pl_ppc_total = make_column_transformer(\n",
    "     (pl_ppc_cat, cat_cols)\n",
    "    ,(pl_ppc_num, num_cols)\n",
    "    ,remainder = 'drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken om in de grid search te kunnen gebruiken\n",
    "pl_gs_total = Pipeline([('preprocess', pl_ppc_total),\n",
    "                       ('clf', LinearRegression())]) # Placeholder Estimator\n",
    "    \n",
    "# param grid waarin alle classifiers + hyper parameters kunnen worden opgenomen. \n",
    "# hier classifiers (modellen) + parameters toevoegen\n",
    "param_grid_total = [{'clf': [LinearRegression()], \n",
    "                     'clf__normalize': NORMALIZE,},\n",
    "                    \n",
    "                    {'clf': [Ridge()],  \n",
    "                     'clf__alpha': ALPHA},\n",
    "                    \n",
    "                    {'clf': [Lasso()], \n",
    "                     'clf__alpha': ALPHA},\n",
    "                   \n",
    "                    {'clf': [KNeighborsRegressor()],  \n",
    "                     'clf__n_neighbors': NEIGHBORS},\n",
    "                     \n",
    "                   {'clf': [SVR()], \n",
    "                    'clf__kernel': KERNEL,\n",
    "                    'clf__C': C_REGULARIZATION},\n",
    "                    \n",
    "                   {'clf': [XGBRegressor()],  \n",
    "                    'clf__gamma': GAMMA,\n",
    "                    'clf__n_estimators': N_ESTIMATORS},                   \n",
    "                   ]\n",
    "    \n",
    "# grid search aanmaken\n",
    "grid_search_total = GridSearchCV(pl_gs_total, param_grid_total, cv=CROSS_VALIDATE,\n",
    "                           scoring=MODEL_SCORING,\n",
    "                           return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#grid search uitvoeren\n",
    "grid_search_total.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_grid_search = pd.DataFrame(grid_search_total.cv_results_)\n",
    "pd_grid_search = pd_grid_search.sort_values('rank_test_score', ascending=True)\n",
    "pd_grid_search.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# de best estimator uit de grid search halen (beste train score)\n",
    "print(f\"Het model met de beste train score is:\\n{grid_search_total.best_estimator_['clf']}\")\n",
    "# de RMSE berekenen voor de best estimator\n",
    "print(f\"Dit model heeft een RMSE van {rsme_from_gridsearch_best_estimator(grid_search_total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dit is het beste model uit de grid search\n",
    "grid_search_total.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "filename = f'../../data/best_model_{suffix_datetime}.pickle'\n",
    "pickle.dump(grid_search_total.best_estimator_, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = get_latest_file(filename_str_contains='best_model_', datapath=datapath, filetype='pickle')\n",
    "# hoe moet ik deze score interpreteren?\n",
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)\n",
    "\n",
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regel om te testen of opgeslagen pickle file overeen komt met model\n",
    "grid_search_total.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OUDE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models_gs_dict = {'Linear Regression': 'grid_search_lr',\n",
    "#                   'Ridge Regression': 'grid_search_rr',\n",
    "#                   'Lasso': 'grid_search_lasso',\n",
    "#                   'K Nearest Neighbor': 'grid_search_knn',\n",
    "#                   'Support Vector Machines': 'grid_search_svm',\n",
    "#                   'XGBoost': 'grid_search_xgb',\n",
    "#                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # nog aan te passen\n",
    "# def append_gridsearch_scores(models_gs_dict):\n",
    "#     for key,item in models_gs_dict.items():\n",
    "#         gridsearch_rsme_scores.append((key,  rsme_from_gridsearch_best_estimator(item)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toevoegen van de beste scores, per model, aan een lijst\n",
    "#gridsearch_rsme_scores = []\n",
    "#gridsearch_rsme_scores.append(('Linear Regression',  rsme_from_gridsearch_best_estimator(grid_search_lr)))\n",
    "#gridsearch_rsme_scores.append(('Ridge Regression',  rsme_from_gridsearch_best_estimator(grid_search_rr)))\n",
    "#gridsearch_rsme_scores.append(('Lasso', rsme_from_gridsearch_best_estimator(grid_search_lasso)))\n",
    "#gridsearch_rsme_scores.append(('K Nearest Neighbor', rsme_from_gridsearch_best_estimator(grid_search_knn)))\n",
    "#gridsearch_rsme_scores.append(('Support Vector Machines', rsme_from_gridsearch_best_estimator(grid_search_svm)))\n",
    "#gridsearch_rsme_scores.append(('XGBoost', rsme_from_gridsearch_best_estimator(grid_search_xgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # maken van een dataframe met daarin de gesorteerde scores per model\n",
    "# #gridsearch_rsme_scores = []\n",
    "# #append_gridsearch_scores(models_gs_dict)\n",
    "# gridsearch_rsme_scores = pd.DataFrame(gridsearch_rsme_scores)\n",
    "# gridsearch_rsme_scores.columns = ['Algorithm', 'RMSE'] \n",
    "# gridsearch_rsme_scores['RMSE'] = gridsearch_rsme_scores['RMSE'].map('{:,.10f}'.format)\n",
    "# gridsearch_rsme_scores = gridsearch_rsme_scores.sort_values('RMSE', ascending=True)\n",
    "# gridsearch_rsme_scores = gridsearch_rsme_scores.reset_index(drop=True)\n",
    "# gridsearch_rsme_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # and the winner is...\n",
    "# print(f\"Het algoritme met de laagste RMSE is:\\n\\n{gridsearch_rsme_scores.iloc[0,0]}, met een RMSE van {gridsearch_rsme_scores.iloc[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model (deze moet nog aangepast worden naar Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Temporary: select best model (needs function)\n",
    "# BEST_SCORE = lasso_scores\n",
    "# index = np.argmax(np.sqrt(-BEST_SCORE['train_neg_mean_squared_error']))\n",
    "# model = BEST_SCORE['estimator'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "# filename = f'../../data/best_model_{suffix_datetime}.pickle'\n",
    "\n",
    "# pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "# joblib.dump(grid.best_estimator_,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test load model (deze moet nog aangepast worden naar Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = get_latest_file(filename_str_contains='best_model_', datapath=datapath, filetype='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = loaded_model.score(X_test, y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extra code, nog opschonen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd_grid_search = pd.DataFrame(grid_search.cv_results_)\n",
    "#pd_grid_search.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_mse = np.sqrt(mean_squared_error(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "#print(f\"{final_mse:.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train pipelines maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor LinearRegression \n",
    "# pl_lr = make_pipeline(\n",
    "#      pl_ppc_total\n",
    "#     ,LinearRegression()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor RidgeRegression \n",
    "# pl_rr = make_pipeline(\n",
    "#      pl_ppc_total\n",
    "#     ,Ridge()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor Lasso\n",
    "# pl_lasso = make_pipeline(\n",
    "#       pl_ppc_total\n",
    "#      ,Lasso(alpha=0.001)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor KNN\n",
    "# pl_knn = make_pipeline(\n",
    "#       pl_ppc_total\n",
    "#      ,KNeighborsRegressor()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor SVR\n",
    "# pl_svm = make_pipeline(\n",
    "#       pl_ppc_total\n",
    "#      ,SVR()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor XGB\n",
    "# pl_xgb = make_pipeline(\n",
    "#       pl_ppc_total\n",
    "#      ,XGBRegressor()\n",
    "# ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lineair Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # scores voor LR berekenen\n",
    "# lr_scores = cross_validate(\n",
    "#     pl_lr, X_train, y_train,\n",
    "#     cv = CROSS_VALIDATE,\n",
    "#     scoring=([MODEL_SCORING]),\n",
    "#     return_train_score=True,\n",
    "#     return_estimator=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rr_scores = cross_validate(\n",
    "#     pl_rr, X_train, y_train,\n",
    "#     cv = CROSS_VALIDATE,\n",
    "#     scoring = ([MODEL_SCORING]),\n",
    "#     return_train_score=True,\n",
    "#     return_estimator=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso_scores = cross_validate(\n",
    "#     pl_lasso, X_train, y_train,\n",
    "#     cv = CROSS_VALIDATE,\n",
    "#     scoring = ([MODEL_SCORING]),\n",
    "#     return_train_score=True,\n",
    "#     return_estimator=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn_scores = cross_validate(\n",
    "#     pl_knn, X_train, y_train,\n",
    "#     cv = CROSS_VALIDATE,\n",
    "#     scoring = ([MODEL_SCORING]),\n",
    "#     return_train_score=True,\n",
    "#     return_estimator=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# svm_scores = cross_validate(\n",
    "#     pl_svm, X_train, y_train,\n",
    "#     cv = CROSS_VALIDATE,\n",
    "#     scoring = ([MODEL_SCORING]),\n",
    "#     return_train_score=True,\n",
    "#     return_estimator=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_scores = cross_validate(\n",
    "#     pl_xgb, X_train, y_train,\n",
    "#     cv = CROSS_VALIDATE,\n",
    "#     scoring = ([MODEL_SCORING]),\n",
    "#     return_train_score=True,\n",
    "#     return_estimator=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # toevoegen van de scores van de best estimator, per gridsearch model, aan een lijst\n",
    "# scores = []\n",
    "# scores.append(('Linear Regression',  get_best_model_rmsle(lr_scores)))\n",
    "# scores.append(('Ridge Regression',  get_best_model_rmsle(rr_scores)))\n",
    "# scores.append(('Lasso', get_best_model_rmsle(lasso_scores)))\n",
    "# scores.append(('K Nearest Neighbor', get_best_model_rmsle(knn_scores)))\n",
    "# scores.append(('Support Vector Machines', get_best_model_rmsle(svm_scores)))\n",
    "# scores.append(('XGBoost', get_best_model_rmsle(xgb_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores.append(('Lasso', get_best_model_rmsle(lasso_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # maken van een dataframe met daarin de gesorteerde scores per model\n",
    "# scores = pd.DataFrame(scores)\n",
    "# scores.columns = ['Algorithm', 'RMSE'] \n",
    "# scores['RMSE'] = scores['RMSE'].map('{:,.10f}'.format)\n",
    "# scores = scores.sort_values('RMSE', ascending=True)\n",
    "# scores = scores.reset_index(drop=True)\n",
    "# scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # and the winner is...\n",
    "# print(f\"Het algoritme met de laagste RMSE is:\\n\\n{scores.iloc[0,0]}, met een RMSE van {scores.iloc[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Temporary: select best model (needs function)\n",
    "# BEST_SCORE = lasso_scores\n",
    "# index = np.argmax(np.sqrt(-BEST_SCORE['train_neg_mean_squared_error']))\n",
    "# model = BEST_SCORE['estimator'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "# filename = f'../../data/best_model_{suffix_datetime}.pickle'\n",
    "\n",
    "# pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model = get_latest_file(filename_str_contains='best_model_', datapath=datapath, filetype='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = loaded_model.score(X_test, y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pipeline maken voor Linear Regression\n",
    "# pl_gs_lr = Pipeline(\n",
    "#      [('preprocess', pl_ppc_total),\n",
    "#      ('model_lr',LinearRegression()) \n",
    "#      ]\n",
    "# )\n",
    "\n",
    "# # pipeline maken voor RidgeRegression\n",
    "# pl_gs_rr = Pipeline(\n",
    "#      [('preprocess', pl_ppc_total),\n",
    "#      ('model_rr',Ridge()) \n",
    "#      ]\n",
    "# )\n",
    "\n",
    "# # pipeline maken voor Lasso\n",
    "# pl_gs_lasso = Pipeline(\n",
    "#      [('preprocess', pl_ppc_total),\n",
    "#        ('model_lasso',Lasso()) \n",
    "#      ]\n",
    "# )\n",
    "\n",
    "# # pipeline maken voor KNN\n",
    "# pl_gs_knn = Pipeline(\n",
    "#      [('preprocess', pl_ppc_total),\n",
    "#        ('model_knn', KNeighborsRegressor()) \n",
    "#      ]\n",
    "# )\n",
    "\n",
    "# # pipeline maken voor SVM\n",
    "# pl_gs_svm = Pipeline(\n",
    "#      [('preprocess', pl_ppc_total),\n",
    "#        ('model_svm', SVR()) \n",
    "#      ]\n",
    "# )\n",
    "\n",
    "# # pipeline maken voor XGB\n",
    "# pl_gs_xgb = Pipeline(\n",
    "#      [('preprocess', pl_ppc_total),\n",
    "#        ('model_xgb',XGBRegressor()) \n",
    "#      ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parameters Linieare Regression\n",
    "# param_grid_lr = [\n",
    "#     {'model_lr__normalize': NORMALIZE},\n",
    "#     ]\n",
    "\n",
    "# # Parameters RidgeRegression\n",
    "# param_grid_rr = [\n",
    "#      {'model_rr__alpha': ALPHA},  \n",
    "#     ]\n",
    "\n",
    "# # Parameters Lasso\n",
    "# param_grid_lasso = [\n",
    "#      {'model_lasso__alpha': ALPHA},  \n",
    "#     ]\n",
    "\n",
    "# # Parameters KNneighbors\n",
    "# param_grid_knn = [\n",
    "#      {'model_knn__n_neighbors': NEIGHBORS },  \n",
    "#     ]\n",
    "\n",
    "# # Parameters SVM\n",
    "# param_grid_svm = [\n",
    "#      {'model_svm__kernel': KERNEL },  \n",
    "#     ]\n",
    "\n",
    "# # Parameters XGB\n",
    "# param_grid_xgb = [\n",
    "#      {'model_xgb__gamma': GAMMA},  \n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Gridsearch LR \n",
    "# grid_search_lr = GridSearchCV(pl_gs_lr, param_grid_lr, cv=CROSS_VALIDATE,\n",
    "#                            scoring=MODEL_SCORING,\n",
    "#                            return_train_score=True)\n",
    "# grid_search_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Gridsearch RR \n",
    "# grid_search_rr = GridSearchCV(pl_gs_rr, param_grid_rr, cv=CROSS_VALIDATE,\n",
    "#                            scoring=MODEL_SCORING,\n",
    "#                            return_train_score=True)\n",
    "# grid_search_rr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Gridsearch Lasso \n",
    "# grid_search_lasso = GridSearchCV(pl_gs_lasso, param_grid_lasso, cv=CROSS_VALIDATE,\n",
    "#                            scoring=MODEL_SCORING,\n",
    "#                            return_train_score=True)\n",
    "# grid_search_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Gridsearch KNN \n",
    "# grid_search_knn = GridSearchCV(pl_gs_knn, param_grid_knn, cv=CROSS_VALIDATE,\n",
    "#                            scoring=MODEL_SCORING,\n",
    "#                            return_train_score=True)\n",
    "# grid_search_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Gridsearch SVM \n",
    "# grid_search_svm = GridSearchCV(pl_gs_svm, param_grid_svm, cv=CROSS_VALIDATE,\n",
    "#                            scoring=MODEL_SCORING,\n",
    "#                            return_train_score=True)\n",
    "# grid_search_svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Gridsearch XGB\n",
    "# grid_search_xgb = GridSearchCV(pl_gs_xgb, param_grid_xgb, cv=CROSS_VALIDATE,\n",
    "#                            scoring=MODEL_SCORING,\n",
    "#                            return_train_score=True)\n",
    "# grid_search_xgb.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
