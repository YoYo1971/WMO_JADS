{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from run_all.main_preprocess import load_data, add_features\n",
    "from utilities.utilities import get_latest_file\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load original sources and combine to one DataFrame\n",
    "df_dataset_WMO = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Feature engineering to get more features\n",
    "df_dataset_WMO_with_features = add_features(df_dataset_WMO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Write temporary result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "\n",
    "# df_dataset_WMO_with_features.to_parquet(f'../../data/df_preprocess_WMO_{suffix_datetime}.parquet.gzip',\n",
    "#               compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Load previous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Continue with loaded data from preprocess\n",
    "df = df_dataset_WMO_with_features.copy()\n",
    "\n",
    "# ## HARDCODED\n",
    "# datapath = '../../data/'\n",
    "# filename = 'df_preprocess_WMO_202103211137.parquet.gzip'\n",
    "# df = pd.read_parquet(datapath + filename)\n",
    "\n",
    "# ## SELECT LAST FILE\n",
    "#datapath = '../../data/'\n",
    "#df = get_latest_file(filename_str_contains='df_preprocess_WMO_', datapath=datapath, filetype='parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zorgen voor de juiste modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV, cross_validate, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, LassoCV, ElasticNet, BayesianRidge\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier, plot_importance\n",
    "\n",
    "from ColumnSelector import ColumnSelector\n",
    "\n",
    "# instellingen voor panda weergave aanpassen\n",
    "pd.set_option('display.max_rows', 500) # alle rijen tonen\n",
    "pd.set_option('display.max_columns', 500) # alle kolommen tonen\n",
    "pd.set_option('display.width', 1000) # kolombreedte\n",
    "pd.set_option(\"display.precision\", 2)     # precisie van de kolommen aanpassen\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) # floats output tot 3 decimalen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframe parameters\n",
    "# locatie van dataset \n",
    "DF_LOCATION = 'C:/_NoBackup/Git/__JADS/WMO_execute_group_project/data/df_dataset_WMO.parquet.gzip'\n",
    "# Location all data\n",
    "datapath = '../../data/'\n",
    "# manier van laden dataset. Bijvoorbeeld read_parquet of read_csv\n",
    "DF_READ = pd.read_parquet\n",
    "\n",
    "## X & Y parameters\n",
    "# de kolommen die uit de X dataset moeten worden gehaald. Dat is in ieder geval de y en eventueel nog meer kolommen.\n",
    "# X_DROP_VALUES = ['wmoclienten', 'eenpersoonshuishoudens', 'huishoudenszonderkinderen', 'huishoudensmetkinderen']\n",
    "X_DROP_VALUES = ['wmoclienten', 'percentagewmoclienten','wmoclientenper1000inwoners']\n",
    "# de kolom die wordt gebruikt als y value\n",
    "Y_VALUE = ['wmoclientenper1000inwoners']\n",
    "# test size voor de train/test split\n",
    "TEST_SIZE = 0.3\n",
    "# random state voor de train/test split. Bijvoorbeeld random_state = 42 als vaste seed voor reproduceerbaarheid\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "## Pipeline parameters\n",
    "# strategy en waarde om te vullen bij lege categorische kolommen\n",
    "NAN_VALUES_CAT_STRATEGY = 'constant'\n",
    "NAN_VALUES_CAT_VALUES = 'Missing'\n",
    "# waarden om in te vullen bij lege numerieke kolommen. Bijvoorbeeld mean of median\n",
    "NAN_VALUES_NUM_STRATEGY = 'mean'\n",
    "# \n",
    "#COLS_SELECT = ['aantalinwoners', 'mannen', 'vrouwen', 'k0tot15jaar'\n",
    "#               , 'k15tot25jaar', 'k25tot45jaar', 'k45tot65jaar', 'k65jaarofouder', 'gescheiden'\n",
    "#               , 'verweduwd', 'westerstotaal', 'sterftetotaal', 'gemiddeldehuishoudensgrootte'\n",
    "#               , 'gemiddeldewoningwaarde', 'koopwoningen', 'huurwoningentotaal', 'inbezitwoningcorporatie'\n",
    "#               , 'gemiddeldinkomenperinkomensontvanger', 'k40personenmetlaagsteinkomen', 'k20personenmethoogsteinkomen'\n",
    "#               , 'actieven1575jaar', 'k40huishoudensmetlaagsteinkomen', 'k20huishoudensmethoogsteinkomen'\n",
    "#               , 'huishoudensmeteenlaaginkomen', 'personenpersoortuitkeringaow', 'rucultuurrecreatieoverigediensten'\n",
    "#               , 'personenautosperhuishouden', 'matevanstedelijkheid']\n",
    "COLS_SELECT = None\n",
    "\n",
    "## Model parameters\n",
    "# manier van cross validate in de modellen. Bijvoorbeeld 10 of RepeatedKFold(n_splits=30, n_repeats=5, random_state=1)\n",
    "CROSS_VALIDATE = 10\n",
    "# manier van scoren in de modellen\n",
    "MODEL_SCORING = 'neg_mean_squared_error'\n",
    "\n",
    "## Scoring parameters\n",
    "# Deze kunnen we later toevoegen als we meerdere manieren van scoren hebben. Dus niet alleen maar de RSMLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functie maken om op basis van de cv scores, het beste RMLSE model te selecteren \n",
    "def get_best_model_rmsle(cv_scores):\n",
    "    \"\"\"\n",
    "    Return best (most conservative) model from cross_validate object.\n",
    "    \n",
    "    Uses np.argmax to find bottomright point == largest RMSE\n",
    "    \"\"\"\n",
    "    index = np.argmax(np.sqrt(-cv_scores['train_neg_mean_squared_error']))\n",
    "    model = cv_scores['estimator'][index]\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Done before start of 'Train' chapter\n",
    "# df = get_latest_file(mypath=datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stappen hieronder mogelijk verplaatsten naar prepare stap, later beoordelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppen van de rijen waar de y_value leeg is, anders kunnen de modellen er niet mee overweg\n",
    "df.dropna(\n",
    "    axis=0,\n",
    "    how='any',\n",
    "    thresh=None,\n",
    "    subset=Y_VALUE,\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X en y aanmaken\n",
    "X = df.drop(X_DROP_VALUES, axis=1)\n",
    "# y = df[Y_VALUE]*100 # 0.01 -> 1.0 percentage\n",
    "y = df[Y_VALUE] # 0.01 -> 1.0 percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitsen van X en y in train/test. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitsen van X_train in categorische en numerieke kolommen, om apart te kunnen transformeren\n",
    "cat_cols = X_train.select_dtypes(include=['category']).columns\n",
    "num_cols = X_train.select_dtypes(include=['int64','float64','float32','int32']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines (pl) maken voor imputing, scaling en OneHotEncoding per datatype \n",
    "\n",
    "# categorie met waarde die is gegeven aan \"MISSING\" toevoegen\n",
    "for col in cat_cols:\n",
    "    # need to add category for missings, otherwise error with OneHotEncoding (volgens mij ook met alleen imputing)\n",
    "    X_train[col].cat.add_categories(NAN_VALUES_CAT_VALUES, inplace=True)\n",
    "categories = [X_train[col].cat.categories for col in cat_cols]\n",
    "\n",
    "# pipeline voor categorial datatype\n",
    "pl_ppc_cat = make_pipeline(\n",
    "     SimpleImputer(\n",
    "         missing_values = np.nan\n",
    "        ,strategy = NAN_VALUES_CAT_STRATEGY\n",
    "        ,fill_value = NAN_VALUES_CAT_VALUES)\n",
    "    ,OneHotEncoder(categories=categories)\n",
    ")\n",
    "\n",
    "# pipeline voor numeriek datatype\n",
    "pl_ppc_num = make_pipeline(\n",
    "      ColumnSelector(cols=COLS_SELECT)\n",
    "    ,SimpleImputer(\n",
    "         missing_values = np.nan\n",
    "        ,strategy = NAN_VALUES_NUM_STRATEGY)\n",
    "    ,StandardScaler()\n",
    "    ,PCA() # PCA heeft behoorlijk wat (positieve) invloed op de scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines maken om de preprocessing van de imputing te combineren\n",
    "pl_ppc_total = make_column_transformer(\n",
    "     (pl_ppc_cat, cat_cols)\n",
    "    ,(pl_ppc_num, num_cols)\n",
    "    ,remainder = 'drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance & feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de X train door bovenstaande pipelines heen halen en opslaan in X_train_prepared\n",
    "X_train_prepared = pl_ppc_total.fit_transform(X_train)\n",
    "# de X_train_prepared weer omzetten naar dataframe, inclusief column names\n",
    "X_train = pd.DataFrame(data=X_train_prepared, columns=[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kiezen van het model waarmee feature importance wordt bepaald, bijvoorbeeld:\n",
    "    # RandomForestRegressor(random_state=42)\n",
    "    # XGBRegressor(n_estimators=100, random_state = 42)\n",
    "FI_MODEL = XGBRegressor(n_estimators=100, random_state = 42)\n",
    "FI_MODEL.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = FI_MODEL.feature_importances_\n",
    "fi_list = sorted(zip(fi, num_cols), reverse=True)\n",
    "# met de [:n] kun je het aantal features aanpassen dat getoond moet worden\n",
    "fi_df_top_n = pd.DataFrame(fi_list[:30])\n",
    "fi_df_top_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.barh(fi_df_top_n[1], fi_df_top_n[0],)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso (cross validate) uitvoeren\n",
    "feature_selection = LassoCV(cv=10).fit(X_train, y_train)\n",
    "# lijst aanmaken met coefficienten per feature\n",
    "feature_selection_coef_list = sorted(zip(np.abs(feature_selection.coef_), num_cols), reverse=True)\n",
    "df_coef = pd.DataFrame(feature_selection_coef_list, columns=['coef','feature']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laat de N features zien met de hoogste coefficienten\n",
    "df_coef.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_0_cols_df = df_coef[df_coef[\"coef\"] == 0]\n",
    "coef_0_cols_list = coef_0['feature'].values.tolist()\n",
    "coef_0_cols_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do (logistic regression/continious waarden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_model_logistic_regression = LogisticRegression()\n",
    "rfe = RFE(feature_importance_model_logistic_regression, 15)\n",
    "fit = rfe.fit(X_train_prepared, y_train)\n",
    "print(\"Num Features: %s\" % (fit.n_features_))\n",
    "print(\"Selected Features: %s\" % (fit.support_))\n",
    "print(\"Feature Ranking: %s\" % (fit.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "sel_ = SelectFromModel(LogisticRegression(C=1, penalty='l1'))\n",
    "sel_.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "GRIDSEARCH_MODEL = RandomForestRegressor(random_state=42)\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(GRIDSEARCH_MODEL, param_grid, cv=2,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "important_attributes = sorted(zip(feature_importances, num_cols), reverse=True)\n",
    "important_attributes[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train pipelines maken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken voor LinearRegression \n",
    "pl_lr = make_pipeline(\n",
    "     pl_ppc_total\n",
    "    ,LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken voor RidgeRegression \n",
    "pl_rr = make_pipeline(\n",
    "     pl_ppc_total\n",
    "    ,Ridge()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken voor Lasso\n",
    "pl_lasso = make_pipeline(\n",
    "      pl_ppc_total\n",
    "     ,Lasso(alpha=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken voor KNN\n",
    "pl_knn = make_pipeline(\n",
    "      pl_ppc_total\n",
    "     ,KNeighborsRegressor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken voor SVM\n",
    "pl_svm = make_pipeline(\n",
    "      pl_ppc_total\n",
    "     ,SVR()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken voor XGB\n",
    "pl_xgb = make_pipeline(\n",
    "      pl_ppc_total\n",
    "     ,XGBRegressor()\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lineair Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores voor LR berekenen\n",
    "lr_scores = cross_validate(\n",
    "    pl_lr, X_train, y_train,\n",
    "    cv = CROSS_VALIDATE,\n",
    "    scoring=([MODEL_SCORING]),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_scores = cross_validate(\n",
    "    pl_rr, X_train, y_train,\n",
    "    cv = CROSS_VALIDATE,\n",
    "    scoring = ([MODEL_SCORING]),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_scores = cross_validate(\n",
    "    pl_lasso, X_train, y_train,\n",
    "    cv = CROSS_VALIDATE,\n",
    "    scoring = ([MODEL_SCORING]),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_scores = cross_validate(\n",
    "    pl_knn, X_train, y_train,\n",
    "    cv = CROSS_VALIDATE,\n",
    "    scoring = ([MODEL_SCORING]),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_scores = cross_validate(\n",
    "    pl_svm, X_train, y_train,\n",
    "    cv = CROSS_VALIDATE,\n",
    "    scoring = ([MODEL_SCORING]),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_scores = cross_validate(\n",
    "    pl_xgb, X_train, y_train,\n",
    "    cv = CROSS_VALIDATE,\n",
    "    scoring = ([MODEL_SCORING]),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toevoegen van de beste scores, per model, aan een lijst\n",
    "scores = []\n",
    "scores.append(('Linear Regression',  get_best_model_rmsle(lr_scores)))\n",
    "scores.append(('Ridge Regression',  get_best_model_rmsle(rr_scores)))\n",
    "scores.append(('Lasso', get_best_model_rmsle(lasso_scores)))\n",
    "scores.append(('K Nearest Neighbor', get_best_model_rmsle(knn_scores)))\n",
    "scores.append(('Support Vector Machines', get_best_model_rmsle(svm_scores)))\n",
    "scores.append(('XGBoost', get_best_model_rmsle(xgb_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maken van een dataframe met daarin de gesorteerde scores per model\n",
    "scores = pd.DataFrame(scores)\n",
    "scores.columns = ['Algorithm', 'RMSE'] \n",
    "scores['RMSE'] = scores['RMSE'].map('{:,.10f}'.format)\n",
    "scores = scores.sort_values('RMSE', ascending=True)\n",
    "scores = scores.reset_index(drop=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the winner is...\n",
    "print(f\"Het algoritme met de laagste RMSE is:\\n\\n{scores.iloc[0,0]}, met een RMSE van {scores.iloc[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary: select best model (needs function)\n",
    "BEST_SCORE = lasso_scores\n",
    "index = np.argmax(np.sqrt(-BEST_SCORE['train_neg_mean_squared_error']))\n",
    "model = BEST_SCORE['estimator'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "filename = f'../../data/best_model_{suffix_datetime}.pickle'\n",
    "\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = get_latest_file(filename_str_contains='best_model_', datapath=datapath, filetype='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
