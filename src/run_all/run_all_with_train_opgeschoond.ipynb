{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from run_all.main_preprocess import load_data, add_features\n",
    "from utilities.utilities import get_latest_file\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Load original sources and combine to one DataFrame\n",
    "# df_dataset_WMO = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Feature engineering to get more features\n",
    "# df_dataset_WMO_with_features = add_features(df_dataset_WMO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Write temporary result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "\n",
    "# df_dataset_WMO_with_features.to_parquet(f'../../data/df_preprocess_WMO_{suffix_datetime}.parquet.gzip',\n",
    "#               compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Load previous dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Continue with loaded data from preprocess\n",
    "#df = df_dataset_WMO_with_features.copy()\n",
    "\n",
    "# ## HARDCODED\n",
    "# datapath = '../../data/'\n",
    "# input_filename = 'df_preprocess_WMO_202103211137.parquet.gzip'\n",
    "# df = pd.read_parquet(datapath + input_filename)\n",
    "\n",
    "# ## SELECT LAST FILE\n",
    "datapath = '../../data/'\n",
    "df = get_latest_file(filename_str_contains='df_preprocess_', datapath=datapath, filetype='parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zorgen voor de juiste modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV, cross_validate, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, LassoCV, ElasticNet, BayesianRidge\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "from ColumnSelector import ColumnSelector\n",
    "\n",
    "# instellingen voor panda weergave aanpassen\n",
    "pd.set_option('display.max_rows', 500) # alle rijen tonen\n",
    "pd.set_option('display.max_columns', 500) # alle kolommen tonen\n",
    "pd.set_option('display.width', 1000) # kolombreedte\n",
    "pd.set_option(\"display.precision\", 2)     # precisie van de kolommen aanpassen\n",
    "pd.set_option('display.float_format', lambda x: '{:.15f}'.format(x)) # floats output tot 15 decimalen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframe parameters\n",
    "# locatie van dataset \n",
    "DF_LOCATION = 'C:/_NoBackup/Git/__JADS/WMO_execute_group_project/data/df_dataset_WMO.parquet.gzip'\n",
    "# Location all data\n",
    "datapath = '../../data/'\n",
    "# manier van laden dataset. Bijvoorbeeld read_parquet of read_csv\n",
    "DF_READ = pd.read_parquet\n",
    "\n",
    "## X & Y parameters\n",
    "# de kolommen die uit de X dataset moeten worden gehaald. Dat is in ieder geval de y en eventueel nog meer kolommen.\n",
    "# X_DROP_VALUES = ['wmoclienten', 'eenpersoonshuishoudens', 'huishoudenszonderkinderen', 'huishoudensmetkinderen']\n",
    "X_DROP_VALUES = ['wmoclienten', 'percentagewmoclienten','wmoclientenper1000inwoners','perioden']\n",
    "# de kolom die wordt gebruikt als y value\n",
    "Y_VALUE = ['wmoclientenper1000inwoners']\n",
    "# test size voor de train/test split\n",
    "TEST_SIZE = 0.3\n",
    "# random state voor de train/test split. Bijvoorbeeld random_state = 42 als vaste seed voor reproduceerbaarheid\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "## Pipeline parameters\n",
    "# strategy en waarde om te vullen bij lege categorische kolommen\n",
    "NAN_VALUES_CAT_STRATEGY = 'constant'\n",
    "NAN_VALUES_CAT_VALUES = 'Missing'\n",
    "# waarden om in te vullen bij lege numerieke kolommen. Bijvoorbeeld mean of median\n",
    "NAN_VALUES_NUM_STRATEGY = 'mean'\n",
    "# \n",
    "#COLS_SELECT = ['aantalinwoners', 'mannen', 'vrouwen', 'k0tot15jaar'\n",
    "#               , 'k15tot25jaar', 'k25tot45jaar', 'k45tot65jaar', 'k65jaarofouder', 'gescheiden'\n",
    "#               , 'verweduwd', 'westerstotaal', 'sterftetotaal', 'gemiddeldehuishoudensgrootte'\n",
    "#               , 'gemiddeldewoningwaarde', 'koopwoningen', 'huurwoningentotaal', 'inbezitwoningcorporatie'\n",
    "#               , 'gemiddeldinkomenperinkomensontvanger', 'k40personenmetlaagsteinkomen', 'k20personenmethoogsteinkomen'\n",
    "#               , 'actieven1575jaar', 'k40huishoudensmetlaagsteinkomen', 'k20huishoudensmethoogsteinkomen'\n",
    "#               , 'huishoudensmeteenlaaginkomen', 'personenpersoortuitkeringaow', 'rucultuurrecreatieoverigediensten'\n",
    "#               , 'personenautosperhuishouden', 'matevanstedelijkheid']\n",
    "COLS_SELECT = None\n",
    "\n",
    "## Model parameters\n",
    "\n",
    "# manier van cross validate in de modellen. Bijvoorbeeld 10 of RepeatedKFold(n_splits=30, n_repeats=5, random_state=1)\n",
    "CROSS_VALIDATE = 5\n",
    "# manier van scoren in de modellen\n",
    "MODEL_SCORING = 'neg_mean_squared_error'\n",
    "## Grid Search parameters\n",
    "\n",
    "# parameters die gebruikt worden in de grid search\n",
    "\n",
    "ALPHA = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "NEIGHBORS = [3, 5, 11, 19]\n",
    "NORMALIZE = [True, False]\n",
    "KERNEL = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
    "GAMMA = [0.5, 1, 1.5, 2, 5]\n",
    "N_ESTIMATORS = [50,100,200]\n",
    "C_REGULARIZATION = [0.001, 0.01, 0,1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_from_specific_columns (df,columns_to_check):\n",
    "    \"\"\"\n",
    "    Drops all rows with nan values in specific columns in a dataframe\n",
    "    \"\"\"\n",
    "    df.dropna(\n",
    "        axis=0,\n",
    "        how='any',\n",
    "        thresh=None,\n",
    "        subset=columns_to_check,\n",
    "        inplace=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_clf_and_params(best_estimator_clf):\n",
    "    \"\"\"\n",
    "    takes best estimator[clf] and outputs a list with clf and parameters\n",
    "    \"\"\"\n",
    "    clf_and_params = str(best_estimator_clf)\n",
    "    clf_and_params = clf_and_params.replace(\")\", \"\")\n",
    "    clf_and_params_split = clf_and_params.split(\"(\")\n",
    "    return clf_and_params_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functie maken om op basis van de grid search best estimator, het beste RMSE model te selecteren \n",
    "def rmse_from_gridsearch_best_estimator(grid_search):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from the grid search best estimator\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_from_neg_mean_squared_error(neg_mean_squared_error):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from the neq mean squared error\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(-(neg_mean_squared_error))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Done before start of 'Train' chapter\n",
    "# df = get_latest_file(mypath=datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stappen hieronder mogelijk verplaatsten naar prepare stap, later beoordelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checken of er rijen in het dataframe zitten waarbij de Y_value leeg is. Die rijen worden eruit gehaald.\n",
    "drop_nan_from_specific_columns(df,Y_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X en y aanmaken\n",
    "X = df.drop(X_DROP_VALUES, axis=1)\n",
    "y = df[Y_VALUE]\n",
    "# splitsen van X en y in train/test. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitsen van X_train in categorische en numerieke kolommen, om apart te kunnen transformeren\n",
    "cat_cols = X_train.select_dtypes(include=['category']).columns\n",
    "num_cols = X_train.select_dtypes(include=['int64','float64','float32','int32']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines (pl) maken voor imputing, scaling en OneHotEncoding per datatype \n",
    "\n",
    "# categorie met waarde die is gegeven aan \"MISSING\" toevoegen\n",
    "for col in cat_cols:\n",
    "    # need to add category for missings, otherwise error with OneHotEncoding (volgens mij ook met alleen imputing)\n",
    "    X_train[col].cat.add_categories(NAN_VALUES_CAT_VALUES, inplace=True)\n",
    "categories = [X_train[col].cat.categories for col in cat_cols]\n",
    "\n",
    "# pipeline voor categorial datatype\n",
    "pl_ppc_cat = make_pipeline(\n",
    "     SimpleImputer(\n",
    "         missing_values = np.nan\n",
    "        ,strategy = NAN_VALUES_CAT_STRATEGY\n",
    "        ,fill_value = NAN_VALUES_CAT_VALUES)\n",
    "    ,OneHotEncoder(categories=categories)\n",
    ")\n",
    "\n",
    "# pipeline voor numeriek datatype\n",
    "pl_ppc_num = make_pipeline(\n",
    "      ColumnSelector(cols=COLS_SELECT)\n",
    "    ,SimpleImputer(\n",
    "         missing_values = np.nan\n",
    "        ,strategy = NAN_VALUES_NUM_STRATEGY)\n",
    "    ,StandardScaler()\n",
    "    #,PCA() # PCA heeft behoorlijk wat (positieve) invloed op de scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines maken om de preprocessing van de imputing te combineren\n",
    "pl_ppc_total = make_column_transformer(\n",
    "     (pl_ppc_cat, cat_cols)\n",
    "    ,(pl_ppc_num, num_cols)\n",
    "    ,remainder = 'drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken om in de grid search te kunnen gebruiken\n",
    "pl_gs_total = Pipeline([('preprocess', pl_ppc_total),\n",
    "                       ('clf', LinearRegression())]) # Placeholder Estimator\n",
    "    \n",
    "# param grid waarin alle classifiers + hyper parameters kunnen worden opgenomen. \n",
    "# hier classifiers (modellen) + parameters toevoegen\n",
    "param_grid_total = [{'clf': [LinearRegression()], \n",
    "                     'clf__normalize': NORMALIZE,},\n",
    "                    \n",
    "                    {'clf': [Ridge()],  \n",
    "                     'clf__alpha': ALPHA},\n",
    "                    \n",
    "                    {'clf': [Lasso()], \n",
    "                     'clf__alpha': ALPHA},\n",
    "                   \n",
    "                 #   {'clf': [KNeighborsRegressor()],  \n",
    "                 #    'clf__n_neighbors': NEIGHBORS},\n",
    "                     \n",
    "                 #  {'clf': [SVR()], \n",
    "                 #   'clf__kernel': KERNEL,\n",
    "                 #   'clf__C': C_REGULARIZATION},\n",
    "                    \n",
    "                   {'clf': [XGBRegressor()],  \n",
    "                    'clf__gamma': GAMMA,\n",
    "                    'clf__n_estimators': N_ESTIMATORS},                   \n",
    "                   ]\n",
    "    \n",
    "# grid search aanmaken\n",
    "grid_search_total = GridSearchCV(pl_gs_total, param_grid_total, cv=CROSS_VALIDATE,\n",
    "                           scoring=MODEL_SCORING,\n",
    "                           return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#grid search uitvoeren\n",
    "grid_search_total.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# de best estimator uit de grid search halen (beste train score)\n",
    "print(f\"Het model met de beste train score is:\\n{grid_search_total.best_estimator_['clf']}\")\n",
    "# de RMSE berekenen voor de best estimator\n",
    "print(f\"Dit model heeft een train score RMSE van {rmse_from_neg_mean_squared_error(grid_search_total.best_score_)}\") \n",
    "print(f\"Dit model heeft een test score RMSE van  {rmse_from_gridsearch_best_estimator(grid_search_total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best model and best model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opslaan van beste estimator vanuit de gridsearch naar een Pickle file\n",
    "suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "output_filename = f'../../data/best_model_{suffix_datetime}.pickle'\n",
    "pickle.dump(grid_search_total.best_estimator_, open(output_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra regel om tijdelijk een dummy bij input_filename te krijgen\n",
    "input_filename = 'Hier komt uiteindelijk de input_filename_locatie'\n",
    "# dictionary maken van alle properties die van het beste model moeten worden opgeslagen\n",
    "best_model_properties_dict = {\"Model\": [split_clf_and_params(grid_search_total.best_estimator_['clf'])[0]],\n",
    "                        \"Gridsearch_Params\": [split_clf_and_params(grid_search_total.best_estimator_['clf'])[1]],\n",
    "                        \"Train_RMSE\": [rmse_from_neg_mean_squared_error(grid_search_total.best_score_)],\n",
    "                        \"Test_RMSE\": [rmse_from_gridsearch_best_estimator(grid_search_total)],\n",
    "                        \"Number_of_features\": [len(X.columns)],\n",
    "                        \"Y_value\": Y_VALUE,\n",
    "                        \"Input_filename\": [input_filename],\n",
    "                        \"Output_filename\": [output_filename],\n",
    "                                     }\n",
    "best_model_properties = pd.DataFrame(best_model_properties_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opslaan van beste model properties naar csv\n",
    "best_model_properties.to_csv(f'../../data/best_model_properties{suffix_datetime}.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combineren van de verschillende best model properties csv's naar één dataframe\n",
    "import os\n",
    "import glob\n",
    "os.chdir(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Gridsearch_Params</th>\n",
       "      <th>Train_RMSE</th>\n",
       "      <th>Test_RMSE</th>\n",
       "      <th>Number_of_features</th>\n",
       "      <th>Y_value</th>\n",
       "      <th>Input_filename</th>\n",
       "      <th>Output_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>alpha=1</td>\n",
       "      <td>0.000875748016430</td>\n",
       "      <td>0.000874619538451</td>\n",
       "      <td>140</td>\n",
       "      <td>wmoclientenper1000inwoners</td>\n",
       "      <td>Hier komt uiteindelijk de input_filename_locatie</td>\n",
       "      <td>../../data/best_model_202104021328.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>alpha=1</td>\n",
       "      <td>0.000875748016430</td>\n",
       "      <td>0.000874619538451</td>\n",
       "      <td>140</td>\n",
       "      <td>wmoclientenper1000inwoners</td>\n",
       "      <td>Hier komt uiteindelijk de input_filename_locatie</td>\n",
       "      <td>../../data/best_model_202104021400.pickle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model Gridsearch_Params        Train_RMSE         Test_RMSE  Number_of_features                     Y_value                                    Input_filename                            Output_filename\n",
       "0  Ridge           alpha=1 0.000875748016430 0.000874619538451                 140  wmoclientenper1000inwoners  Hier komt uiteindelijk de input_filename_locatie  ../../data/best_model_202104021328.pickle\n",
       "0  Ridge           alpha=1 0.000875748016430 0.000874619538451                 140  wmoclientenper1000inwoners  Hier komt uiteindelijk de input_filename_locatie  ../../data/best_model_202104021400.pickle"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combineren van de verschillende best model properties csv's naar één dataframe\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format('csv'))]\n",
    "#combine all files in the list\n",
    "combined_df = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code voor testen pickle file & predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickle file inladen voor predict\n",
    "# loaded_model = get_latest_file(output_filename_str_contains='best_model_', datapath=datapath, filetype='pickle')\n",
    "# # hoe moet ik deze score interpreteren?\n",
    "# result = loaded_model.score(X_test, y_test)\n",
    "# print(result)\n",
    "# loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regel om te testen of opgeslagen pickle file overeen komt met model\n",
    "#grid_search_total.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dit is het beste model uit de grid search\n",
    "#grid_search_total.best_estimator_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
