{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV, cross_validate, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, LassoCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "# Custom functions\n",
    "import src.settings as settings\n",
    "import src.mapper_cols as mapper_cols\n",
    "from src.run_all.main_get_data import get_data\n",
    "from src.run_all.main_preprocess import preprocess_data\n",
    "from src.utilities.utilities import get_latest_file, list_filenames\n",
    "\n",
    "# instellingen voor panda weergave aanpassen\n",
    "pd.set_option('display.max_rows', 500) # alle rijen tonen\n",
    "pd.set_option('display.max_columns', 500) # alle kolommen tonen\n",
    "pd.set_option('display.width', 1000) # kolombreedte\n",
    "pd.set_option(\"display.precision\", 2)     # precisie van de kolommen aanpassen\n",
    "pd.set_option('display.float_format', lambda x: '{:.15f}'.format(x)) # floats output tot 15 decimalen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location all data\n",
    "datapath = '../../data/'\n",
    "# Drop target values in X set\n",
    "X_DROP_VALUES = settings.Y_TARGET_COLS\n",
    "# de kolom die wordt gebruikt als y value\n",
    "Y_VALUE = ['wmoclientenper1000inwoners']\n",
    "# test size voor de train/test split\n",
    "TEST_SIZE = 0.3\n",
    "# random state voor de train/test split. Bijvoorbeeld random_state = 42 als vaste seed voor reproduceerbaarheid\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "## Model parameters\n",
    "# manier van cross validate in de modellen. Bijvoorbeeld 10 of RepeatedKFold(n_splits=30, n_repeats=5, random_state=1)\n",
    "CROSS_VALIDATE = 5\n",
    "# manier van scoren in de modellen\n",
    "MODEL_SCORING = 'neg_mean_squared_error'\n",
    "## Grid Search parameters\n",
    "\n",
    "# parameters die gebruikt worden in de grid search\n",
    "ALPHA = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "NEIGHBORS = [3, 5, 11, 19]\n",
    "NORMALIZE = [True, False]\n",
    "KERNEL = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
    "GAMMA = [0.5, 1, 1.5, 2, 5]\n",
    "N_ESTIMATORS = [50,100,200]\n",
    "C_REGULARIZATION = [0.001, 0.01, 0,1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_from_specific_columns (df,columns_to_check):\n",
    "    \"\"\"\n",
    "    Drops all rows with nan values in specific columns in a dataframe\n",
    "    \"\"\"\n",
    "    df.dropna(\n",
    "        axis=0,\n",
    "        how='any',\n",
    "        thresh=None,\n",
    "        subset=columns_to_check,\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "def split_clf_and_params(best_estimator_clf):\n",
    "    \"\"\"\n",
    "    Takes best estimator[clf] and outputs a list with clf and parameters\n",
    "    \"\"\"\n",
    "    clf_and_params = str(best_estimator_clf)\n",
    "    clf_and_params = clf_and_params.replace(\")\", \"\")\n",
    "    clf_and_params_split = clf_and_params.split(\"(\")\n",
    "    return clf_and_params_split\n",
    "\n",
    "def rmse_from_neg_mean_squared_error(neg_mean_squared_error):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from the neq mean squared error\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(-(neg_mean_squared_error))\n",
    "    return (rmse)\n",
    "\n",
    "# functie maken om op basis van de grid search best estimator, het beste RMSE model te selecteren \n",
    "def rmse_from_gridsearch_best_estimator(grid_search):\n",
    "    \"\"\"\n",
    "    Calculates RMSE from the grid search best estimator\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, grid_search.best_estimator_.predict(X_test)))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data\n",
    "This step will load and combine several tables from CBS statline. \n",
    "\n",
    "Note: This step takes a number of minutes and without changes to the settings will give the same result. Therefor this code is commented out and the original dataset is loaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "# ## CREATE NEW DATASET\n",
    "# df_get_data_WMO= get_data(save_all=True)\n",
    "\n",
    "# ## HARDCODED\n",
    "datapath = '../../data/'\n",
    "filename = 'df_get_data_WMO_WIJK_HUISHOUDENS_BEVOLKING_HEFFING_202104042111.parquet.gzip'\n",
    "df_get_data_WMO = pd.read_parquet(datapath + filename)\n",
    "\n",
    "# ## SELECT LAST FILE\n",
    "# datapath = '../../data/'\n",
    "# df = get_latest_file(filename_str_contains='df_WMO_', datapath=datapath, filetype='parquet')\n",
    "\n",
    "print(f\"The shape of the dataframe from step 'Get Data': {df_get_data_WMO.shape}\")\n",
    "df_get_data_WMO.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess --> Create test sets\n",
    "This step will transform (select columns, impute, scale) the dataframe to be used in train/predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "df_preprocessed = preprocess_data(df=df_get_data_WMO, save_all=True)\n",
    "\n",
    "print(f\"The shape of the dataframe from step 'Preprocess': {df_preprocessed.shape}\")\n",
    "df_preprocessed.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For testing train\n",
    "# datapath = '../../data/'\n",
    "# filename = 'df_preprocessed_202104042029_Boerenverstand_Maikel.parquet.gzip'\n",
    "# df = pd.read_parquet(datapath + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_preprocessed.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stappen hieronder mogelijk verplaatsten naar prepare stap, later beoordelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checken of er rijen in het dataframe zitten waarbij de Y_value leeg is. Die rijen worden eruit gehaald.\n",
    "drop_nan_from_specific_columns(df,Y_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X en y aanmaken\n",
    "X = df.drop(X_DROP_VALUES, axis=1)\n",
    "y = df[Y_VALUE]\n",
    "# splitsen van X en y in train/test. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken om in de grid search te kunnen gebruiken\n",
    "pl_gs_total = Pipeline([('clf', LinearRegression())]) # Placeholder Estimator\n",
    "    \n",
    "# param grid waarin alle classifiers + hyper parameters kunnen worden opgenomen. \n",
    "# hier classifiers (modellen) + parameters toevoegen\n",
    "param_grid_total = [{'clf': [LinearRegression()], \n",
    "                     'clf__normalize': NORMALIZE,},\n",
    "                    \n",
    "                    {'clf': [Ridge()],  \n",
    "                     'clf__alpha': ALPHA},\n",
    "                    \n",
    "                    {'clf': [Lasso()], \n",
    "                     'clf__alpha': ALPHA},\n",
    "                   \n",
    "                    {'clf': [KNeighborsRegressor()],  \n",
    "                     'clf__n_neighbors': NEIGHBORS},\n",
    "                     \n",
    "                  # {'clf': [SVR()], \n",
    "                  #  'clf__kernel': KERNEL,\n",
    "                  #  'clf__C': C_REGULARIZATION},\n",
    "                    \n",
    "                   {'clf': [XGBRegressor()],  \n",
    "                    'clf__gamma': GAMMA,\n",
    "                    'clf__n_estimators': N_ESTIMATORS},                   \n",
    "                   ]\n",
    "    \n",
    "# grid search aanmaken\n",
    "grid_search_total = GridSearchCV(pl_gs_total, param_grid_total, cv=CROSS_VALIDATE,\n",
    "                           scoring=MODEL_SCORING,\n",
    "                           return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#grid search uitvoeren\n",
    "grid_search_total.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# de best estimator uit de grid search halen (beste train score)\n",
    "print(f\"Het model met de beste train score is:\\n{grid_search_total.best_estimator_['clf']}\")\n",
    "# de RMSE berekenen voor de best estimator\n",
    "print(f\"Dit model heeft een train score RMSE van {rmse_from_neg_mean_squared_error(grid_search_total.best_score_)}\") \n",
    "print(f\"Dit model heeft een test score RMSE van  {rmse_from_gridsearch_best_estimator(grid_search_total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save best model and best model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opslaan van beste estimator vanuit de gridsearch naar een Pickle file\n",
    "suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "output_filename = f'../../data/best_model_{suffix_datetime}.pickle'\n",
    "pickle.dump(grid_search_total.best_estimator_, open(output_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra regel om tijdelijk een dummy bij input_filename te krijgen\n",
    "input_filename = 'Hier komt uiteindelijk de input_filename_locatie'\n",
    "# dictionary maken van alle properties die van het beste model moeten worden opgeslagen\n",
    "best_model_properties_dict = {\"Model\": [split_clf_and_params(grid_search_total.best_estimator_['clf'])[0]],\n",
    "                        \"Gridsearch_Params\": [split_clf_and_params(grid_search_total.best_estimator_['clf'])[1]],\n",
    "                        \"Train_RMSE\": [rmse_from_neg_mean_squared_error(grid_search_total.best_score_)],\n",
    "                        \"Test_RMSE\": [rmse_from_gridsearch_best_estimator(grid_search_total)],\n",
    "                        \"Number_of_features\": [len(X.columns)],\n",
    "                        \"Y_value\": Y_VALUE,\n",
    "                        \"Input_filename\": [input_filename],\n",
    "                        \"Output_filename\": [output_filename],\n",
    "                                     }\n",
    "best_model_properties = pd.DataFrame(best_model_properties_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opslaan van beste model properties naar csv\n",
    "best_model_properties.to_csv(f'../../data/log_train/best_model_properties_{suffix_datetime}.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code voor combineren output CSV's voor visualisatie en vergelijking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## combineren van de verschillende best model properties csv's naar één dataframe\n",
    "# all_filenames = list_filenames(settings.train['LOG_PATH'], filename_str_contains='.csv')\n",
    "# combined_logging = pd.concat([pd.read_csv(f\"{settings.train['LOG_PATH']}{f}\") for f in all_filenames ])\n",
    "# combined_logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code voor testen pickle file & predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pickle file inladen voor predict\n",
    "# loaded_model = get_latest_file(output_filename_str_contains='best_model_', datapath=datapath, filetype='pickle')\n",
    "# # hoe moet ik deze score interpreteren?\n",
    "# result = loaded_model.score(X_test, y_test)\n",
    "# print(result)\n",
    "# loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regel om te testen of opgeslagen pickle file overeen komt met model\n",
    "#grid_search_total.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dit is het beste model uit de grid search\n",
    "#grid_search_total.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
