{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess - Prepare_data\n",
    "This notebook is used to prepare the data. For both training as predicting the same pipeline is used, but with a slight difference in the resulting output (with/without target variable). For The goal is a Xy-dataset in parquet format, with:\n",
    "* For training:\n",
    "    - The number of WMO-clients is the target-variable y. \n",
    "    - A number of columns with features\n",
    "    - Index contains a region and time interval\n",
    "    - Scaled / normalised according to type of variable\n",
    "    - Filename contains a datetime suffix\n",
    "* For predicting:\n",
    "    - A number of columns with features\n",
    "    - Index contains a region and time interval\n",
    "    - Scaled / normalised according to type of variable\n",
    "    - Filename contains a datetime suffix\n",
    "\n",
    "## Content\n",
    "* **Imports**: Imports of needed Python packages\n",
    "* **Settings**: Hard coded variables needed to collect data like sources, tablenames, columnnames, etc. \n",
    "* **Funtions**: Resuable functions\n",
    "* **Load data**: Load data to prepare dataset\n",
    "* **Transform / prepare dataset**: Combining all data to one table\n",
    "* **Write result**: Writing result to '../data'\n",
    "* **Appendix**: Usefull code to preserve\n",
    "    * ...\n",
    "\n",
    "## Requirements\n",
    "The packages to be installed (besides standard Python packages) are:\n",
    "* pandas >=1.1.5\n",
    "* cbsodata >=1.3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import cbsodata\n",
    "from datetime import datetime\n",
    "\n",
    "from typing import Union\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Set the variables right below!\n",
    "# True if prepare train dataset, False if prepare predict dataset\n",
    "train=True \n",
    "\n",
    "\n",
    "# General settings:\n",
    "# Location all data\n",
    "datapath = '../data/'\n",
    "\n",
    "DICT_REALTIVELY_COLS = {'aantalinwoners': ['percentagewmoclienten', 'mannen', 'vrouwen', 'k0tot15jaar', 'k15tot25jaar',\n",
    "                                           'k25tot45jaar', 'k45tot65jaar', 'k65jaarofouder', 'ongehuwd', 'gehuwd', 'gescheiden',\n",
    "                                           'verweduwd', 'westerstotaal', 'nietwesterstotaal', 'marokko', \n",
    "                                           'nederlandseantillenenaruba', 'suriname', 'turkije', 'overignietwesters', \n",
    "                                           'geboortetotaal', 'geboorterelatief', 'sterftetotaal', 'sterfterelatief', \n",
    "                                           'aantalinkomensontvangers', 'personenpersoortuitkeringbijstand', \n",
    "                                           'personenpersoortuitkeringao', 'personenpersoortuitkeringww', \n",
    "                                           'personenpersoortuitkeringaow'],\n",
    "                        'huishoudenstotaal': ['eenpersoonshuishoudens', 'huishoudenszonderkinderen', 'huishoudensmetkinderen'],\n",
    "                        'bedrijfsvestigingentotaal': ['alandbouwbosbouwenvisserij', 'bfnijverheidenenergie', \n",
    "                                                      'gihandelenhoreca', 'hjvervoerinformatieencommunicatie', \n",
    "                                                      'klfinancieledienstenonroerendgoed', 'mnzakelijkedienstverlening', \n",
    "                                                      'rucultuurrecreatieoverigediensten'],\n",
    "                        'personenautostotaal': ['personenautosbrandstofbenzine', 'personenautosoverigebrandstof'],\n",
    "                        'oppervlaktetotaal': ['oppervlakteland', 'oppervlaktewater']}\n",
    "LIST_NORM_COLS = ['wmoclienten', 'aantalinwoners', 'huishoudenstotaal', 'gemiddeldehuishoudensgrootte', 'bevolkingsdichtheid', \n",
    "                  'woningvoorraad', 'gemiddeldewoningwaarde', 'percentageeengezinswoning', 'percentagemeergezinswoning', \n",
    "                  'percentagebewoond', 'percentageonbewoond', 'koopwoningen', 'huurwoningentotaal', 'inbezitwoningcorporatie', \n",
    "                  'inbezitoverigeverhuurders', 'eigendomonbekend', 'bouwjaarvoor2000', 'bouwjaarvanaf2000', \n",
    "                  'gemiddeldelektriciteitsverbruiktotaal', 'gemelectriciteitsverbruikappartement', \n",
    "                  'gemelectriciteitsverbruiktussenwoning', 'gemelectriciteitsverbruikhoekwoning', \n",
    "                  'gemelectriciteitsverbruiktweeondereenkapwoning', 'gemelectriciteitsverbruikvrijstaandewoning', \n",
    "                  'gemelectriciteitsverbruikhuurwoning', 'gemelectriciteitsverbruikeigenwoning', \n",
    "                  'gemiddeldaardgasverbruiktotaal', 'gemgasverbruikappartement', 'gemgasverbruiktussenwoning', \n",
    "                  'gemgasverbruikhoekwoning', 'gemgasverbruiktweeondereenkapwoning', 'gemgasverbruikvrijstaandewoning', \n",
    "                  'gemgasverbruikhuurwoning', 'gemgasverbruikeigenwoning', 'percentagewoningenmetstadsverwarming',\n",
    "                  'gemiddeldinkomenperinkomensontvanger', 'gemiddeldinkomenperinwoner', 'k40personenmetlaagsteinkomen', \n",
    "                  'k20personenmethoogsteinkomen', 'actieven1575jaar', 'k40huishoudensmetlaagsteinkomen', \n",
    "                  'k20huishoudensmethoogsteinkomen', 'huishoudensmeteenlaaginkomen', 'huishonderofrondsociaalminimum',\n",
    "                  'bedrijfsvestigingentotaal', 'personenautostotaal', 'motorfietsen', 'afstandtothuisartsenpraktijk', \n",
    "                  'afstandtotgrotesupermarkt', 'afstandtotkinderdagverblijf', 'afstandtotschool', 'scholenbinnen3km',\n",
    "                  'oppervlaktetotaal', 'matevanstedelijkheid', 'omgevingsadressendichtheid']\n",
    "# DROP_COLS = ['financieringsvorm', 'wmoclientenper1000inwoners', 'gemeentenaam', 'meestvoorkomendepostcode', 'dekkingspercentage', 'totaaldiefstaluitwoningschuured', \n",
    "#                'vernielingmisdrijftegenopenbareorde', 'geweldsenseksuelemisdrijven', 'personenautosjongerdan6jaar', \n",
    "#                'personenautos6jaarenouder', 'bedrijfsmotorvoertuigen']\n",
    "DROP_COLS = ['financieringsvorm', 'gemeentenaam', 'meestvoorkomendepostcode', 'dekkingspercentage', 'totaaldiefstaluitwoningschuured', \n",
    "               'vernielingmisdrijftegenopenbareorde', 'geweldsenseksuelemisdrijven', 'personenautosjongerdan6jaar', \n",
    "               'personenautos6jaarenouder', 'bedrijfsmotorvoertuigen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_file(datapath='../data/', train=True):\n",
    "    \"\"\"\n",
    "    Method to get the latest file to preprare\n",
    "    \n",
    "    :params str datapath: String with the (respectively) directory where the data can be found. Default = '../data'\n",
    "    :params bool train: Boolean to indicate if expected dataframe should be for preparing training data. Default = True\n",
    "    \n",
    "    return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # Get list with file\n",
    "    onlyfiles = sorted([f for f in listdir(datapath) if isfile(join(datapath, f))])\n",
    "    # Get last file\n",
    "    if train:\n",
    "        filename = [s for s in onlyfiles if \"df_get_for_train_WMO\" in s][-1]\n",
    "    else:\n",
    "        filename = [s for s in onlyfiles if \"df_get_for_predict\" in s][-1]\n",
    "    # Get list with last files\n",
    "    df = pd.read_parquet(datapath+filename)\n",
    "    return df\n",
    "\n",
    "\n",
    "class RelativeColumnScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This is a transformer class to scale a (number of) column(s) based on another column.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dict_relatively_cols=None):\n",
    "        \"\"\"\n",
    "        :param dict(str:list[str]) dict_relatively_cols: Dictionary with the base column as key and as a value a list with one \n",
    "                                                         or more columnsnames that need to be transformed. \n",
    "        \"\"\"\n",
    "        self.dict_relatively_cols = dict_relatively_cols\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Standard fit method of transformer (selects all columns in columns arg is None)\n",
    "\n",
    "        :param pd.DataFrame X: Enables a DataFrame as input\n",
    "        :param pd.Series y: Enables a target as input\n",
    "        \n",
    "        :return: return object itself\n",
    "        \"\"\"\n",
    "        # nothing to fit here people, move along\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X) -> Union[pd.DataFrame, pd.Series]:\n",
    "        \"\"\"\n",
    "        Standard transform method of transformer which scales the columns based on a base column.\n",
    "\n",
    "        :param (pd.DataFrame) X: DataFrame to select and transform columns from\n",
    "        \n",
    "        :return: pd.DataFrame or pd.Series containing only the selected columns\n",
    "        \"\"\"\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "     \n",
    "        try:\n",
    "            for base_col, relatively_cols in self.dict_relatively_cols.items():\n",
    "                X[relatively_cols] = X[relatively_cols].div(X[base_col], axis=0)\n",
    "            return X\n",
    "        except KeyError:\n",
    "            colslist = [item for sublist in list(self.dict_relatively_cols.values()) for item in sublist]\n",
    "            cols_error = list(set(colslist) - set(X.columns))\n",
    "            raise KeyError(\"The DataFrame does not include the columns: %s\" % cols_error)\n",
    "\n",
    "            \n",
    "class CustomScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    This is a transformer class to scale the selected columns using a defined scaler\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cols, scaler):\n",
    "        \"\"\"\n",
    "\n",
    "        :param list[str] cols: List of columns to be selected.\n",
    "        :param scaler: Scaler to apply, i.e. MinMaxScaler() from sklearn\n",
    "        \"\"\"\n",
    "        self.cols = cols\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Standard fit method of transformer which fits the scaler to X\n",
    "\n",
    "        :param pd.DataFrame X: DataFrame with the feature columns, including the column(s) to scale\n",
    "        :param pd.Series y: Default None, not used in fit. The target values in a model\n",
    "        :return: Fitted scaler for the selected column(s)\n",
    "        \"\"\"\n",
    "\n",
    "        self.cols = [c for c in self.cols if c in X.columns]\n",
    "        self.scaler.fit(X[self.cols])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Standard transform method of transformer which transforms the dataset with a scaler for the\n",
    "        selected column(s)\n",
    "\n",
    "        :param pd.DataFrame X: DataFrame with the feature columns, including the categorical column(s)\n",
    "        :return: Transformed dataset X (with scaler as defined) for the selected column(s)\n",
    "        \"\"\"\n",
    "\n",
    "        X = X.copy()\n",
    "        X.loc[:, self.cols] = self.scaler.transform(X[self.cols])\n",
    "\n",
    "        return X\n",
    "            \n",
    "    \n",
    "# def make_cols_relatively(df, dict_relatively_cols):\n",
    "#     for base_col, relatively_cols in dict_relatively_cols.items():\n",
    "#         df[relatively_cols] = df[relatively_cols].div(df[base_col], axis=0)\n",
    "#     return df\n",
    "\n",
    "# def normalize_cols(df, norm_cols):\n",
    "#     df_sub = df.copy()\n",
    "#     df_sub = df_sub[norm_cols]\n",
    "#     x = df_sub.values #returns a numpy array\n",
    "#     min_max_scaler = preprocessing.MinMaxScaler()\n",
    "#     x_scaled = min_max_scaler.fit_transform(x)\n",
    "#     df_sub=pd.DataFrame(x_scaled, columns=df_sub.columns, index=df_sub.index)\n",
    "#     df = df.drop(norm_cols, axis=1).join(df_sub)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_get_data = get_latest_file(datapath=datapath, train=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform / prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_get_data.copy()\n",
    "if train:\n",
    "    df['percentagewmoclienten'] = df['wmoclienten']\n",
    "    df = df.drop(DROP_COLS, axis=1)\n",
    "    pl_prepare = make_pipeline(RelativeColumnScaler(dict_relatively_cols=DICT_REALTIVELY_COLS),\n",
    "                               CustomScaler(cols=LIST_NORM_COLS, scaler=preprocessing.MinMaxScaler()))\n",
    "    df_prep = pl_prepare.fit_transform(df)\n",
    "else:\n",
    "    df = df.drop(DROP_COLS, axis=1)\n",
    "    pl_prepare = make_pipeline(RelativeColumnScaler(dict_relatively_cols=DICT_REALTIVELY_COLS),\n",
    "                               CustomScaler(cols=LIST_NORM_COLS, scaler=preprocessing.MinMaxScaler()))\n",
    "    df_prep = pl_prepare.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = df_get_data.copy()\n",
    "# df['percentagewmoclienten'] = df['wmoclienten']\n",
    "# df = df.drop(DROP_COLS, axis=1)\n",
    "# df = make_cols_relatively(df=df, dict_relatively_cols=DICT_REALTIVELY_COLS)\n",
    "# df = normalize_cols(df=df, norm_cols=LIST_NORM_COLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "\n",
    "if train:\n",
    "    df_prep.to_parquet(f'../data/df_prep_for_train_WMO_{suffix_datetime}.parquet.gzip',\n",
    "              compression='gzip')\n",
    "else:\n",
    "    df_prep.to_parquet(f'../data/df_prep_for_predict_WMO_{suffix_datetime}.parquet.gzip',\n",
    "              compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "## Code examples to get a subset of the DataFrame based on multiindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemeentenaam regels moeten nog gefixt worden\n",
    "# Subset on columnvalue:\n",
    "#df_prep[df_prep['gemeentenaam']=='Nijmegen']\n",
    "\n",
    "# One row / record\n",
    "df_prep.loc[('WK026801', '2019')]\n",
    "\n",
    "# Multiple rows / records based on combination of the multiindex\n",
    "df_prep.loc[[('WK026801', '2018'), ('WK026802', '2018')]]\n",
    "\n",
    "# Multiple rows / records for one column (works only for series)\n",
    "#df_prep['gemeentenaam'].loc[(['WK026801', 'WK026802'], ['2018', '2019'])]\n",
    "\n",
    "# Multiple rows based on both indexes:\n",
    "df_prep.loc(axis=0)[['WK026801', 'WK026802'], ['2018', '2019']]\n",
    "\n",
    "# Subset with IndexSlice\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# Subset on one of the multiindex and select a column\n",
    "#df_prep.loc[idx[:, ['2018', '2019']], idx[\"gemeentenaam\"]]\n",
    "\n",
    "# Subset on one of the multiindex and select all columns\n",
    "df_prep.loc[idx['WK026801', :], idx[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_prep[df_prep['gemeentenaam']=='Nijmegen']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to get current versions of loaded packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n'.join(f'{m.__name__} {m.__version__}' for m in globals().values() if getattr(m, '__version__', None)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
