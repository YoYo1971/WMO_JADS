{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "This notebook is used to train the model. For The goal is to try multiple settings and models to find the best model. This model will be saved in a pickle file. \n",
    "\n",
    "## Content\n",
    "* **Imports**: Imports of needed Python packages\n",
    "* **Settings**: Hard coded variables needed to collect data like sources, tablenames, columnnames, etc. \n",
    "* **Funtions**: Resuable functions\n",
    "* **Load data**: Load data\n",
    "* **Pipelines**: Create pipelines\n",
    "* **Train**: Train and fit best model\n",
    "* **Evaluate**: Evaluate the model\n",
    "    * **Scorings metric**\n",
    "    * **Feature importance**\n",
    "* **Save model**: Writing result to '../data'\n",
    "\n",
    "## Requirements\n",
    "The packages to be installed (besides standard Python packages) are:\n",
    "* later invullen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zorgen voor de juiste modules\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV, cross_validate, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, LassoCV, ElasticNet, BayesianRidge\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from ColumnSelector import ColumnSelector\n",
    "\n",
    "# instellingen voor panda weergave aanpassen\n",
    "pd.set_option('display.max_rows', 500) # alle rijen tonen\n",
    "pd.set_option('display.max_columns', 500) # alle kolommen tonen\n",
    "pd.set_option('display.width', 1000) # kolombreedte\n",
    "pd.set_option(\"display.precision\", 2)     # precisie van de kolommen aanpassen\n",
    "pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) # floats output tot 3 decimalen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataframe parameters\n",
    "# locatie van dataset \n",
    "DF_LOCATION = 'C:/_NoBackup/Git/__JADS/WMO_execute_group_project/data/df_dataset_WMO.parquet.gzip'\n",
    "# Location all data\n",
    "datapath = '../data/'\n",
    "# manier van laden dataset. Bijvoorbeeld read_parquet of read_csv\n",
    "DF_READ = pd.read_parquet\n",
    "\n",
    "## X & Y parameters\n",
    "# de kolommen die uit de X dataset moeten worden gehaald. Dat is in ieder geval de y en eventueel nog meer kolommen.\n",
    "# X_DROP_VALUES = ['wmoclienten', 'eenpersoonshuishoudens', 'huishoudenszonderkinderen', 'huishoudensmetkinderen']\n",
    "X_DROP_VALUES = ['wmoclienten', 'percentagewmoclienten','wmoclientenper1000inwoners']\n",
    "# de kolom die wordt gebruikt als y value\n",
    "Y_VALUE = ['wmoclientenper1000inwoners']\n",
    "# test size voor de train/test split\n",
    "TEST_SIZE = 0.3\n",
    "# random state voor de train/test split. Bijvoorbeeld random_state = 42 als vaste seed voor reproduceerbaarheid\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "## Pipeline parameters\n",
    "# strategy en waarde om te vullen bij lege categorische kolommen\n",
    "NAN_VALUES_CAT_STRATEGY = 'constant'\n",
    "NAN_VALUES_CAT_VALUES = 'Missing'\n",
    "# waarden om in te vullen bij lege numerieke kolommen. Bijvoorbeeld mean of median\n",
    "NAN_VALUES_NUM_STRATEGY = 'mean'\n",
    "# \n",
    "#COLS_SELECT = ['aantalinwoners', 'mannen', 'vrouwen', 'k0tot15jaar'\n",
    "#               , 'k15tot25jaar', 'k25tot45jaar', 'k45tot65jaar', 'k65jaarofouder', 'gescheiden'\n",
    "#               , 'verweduwd', 'westerstotaal', 'sterftetotaal', 'gemiddeldehuishoudensgrootte'\n",
    "#               , 'gemiddeldewoningwaarde', 'koopwoningen', 'huurwoningentotaal', 'inbezitwoningcorporatie'\n",
    "#               , 'gemiddeldinkomenperinkomensontvanger', 'k40personenmetlaagsteinkomen', 'k20personenmethoogsteinkomen'\n",
    "#               , 'actieven1575jaar', 'k40huishoudensmetlaagsteinkomen', 'k20huishoudensmethoogsteinkomen'\n",
    "#               , 'huishoudensmeteenlaaginkomen', 'personenpersoortuitkeringaow', 'rucultuurrecreatieoverigediensten'\n",
    "#               , 'personenautosperhuishouden', 'matevanstedelijkheid']\n",
    "COLS_SELECT = None\n",
    "\n",
    "## Model parameters\n",
    "# manier van cross validate in de modellen. Bijvoorbeeld 10 of RepeatedKFold(n_splits=30, n_repeats=5, random_state=1)\n",
    "CROSS_VALIDATE = 10\n",
    "# manier van scoren in de modellen\n",
    "MODEL_SCORING = 'neg_mean_squared_error'\n",
    "\n",
    "## Scoring parameters\n",
    "# Deze kunnen we later toevoegen als we meerdere manieren van scoren hebben. Dus niet alleen maar de RSMLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_file(mypath='../data/'):\n",
    "    \"\"\"\n",
    "    Method to get the latest file to preprare\n",
    "    \n",
    "    :params str mypath: String with the (respectively) directory where the data can be found. Default = '../data'\n",
    "    :params bool train: Boolean to indicate if expected dataframe should be for preparing training data. Default = True\n",
    "    \n",
    "    return: pd.DataFrame\n",
    "    \"\"\"\n",
    "    # Get list with file\n",
    "    onlyfiles = sorted([f for f in listdir(mypath) if isfile(join(mypath, f))])\n",
    "    filename = [s for s in onlyfiles if \"df_prep_for_train_WMO\" in s][-1]\n",
    "    # Get list with last files\n",
    "    df = pd.read_parquet(mypath+filename)\n",
    "    return df\n",
    "\n",
    "def get_latest_pickle_file(datapath='../data/'):\n",
    "    \"\"\"\n",
    "    Method to get the latest file to preprare\n",
    "    \n",
    "    :params str datapath: String with the (respectively) directory where the data can be found. Default = '../data'\n",
    "    :params bool train: Boolean to indicate if expected dataframe should be for preparing training data. Default = True\n",
    "    \n",
    "    return: pickle model\n",
    "    \"\"\"\n",
    "    # Get list with file\n",
    "    onlyfiles = sorted([f for f in listdir(datapath) if isfile(join(datapath, f))])\n",
    "    # Get last file\n",
    "    filename = [s for s in onlyfiles if \"best_model\" in s][-1]\n",
    "    # Get list with last files\n",
    "    model = pickle.load(open(datapath+filename, 'rb'))\n",
    "    return model\n",
    "\n",
    "# functie maken om op basis van de cv scores, het beste RMLSE model te selecteren \n",
    "def get_best_model_rmsle(cv_scores):\n",
    "    \"\"\"\n",
    "    Return best (most conservative) model from cross_validate object.\n",
    "    \n",
    "    Uses np.argmax to find bottomright point == largest RMSE\n",
    "    \"\"\"\n",
    "    index = np.argmax(np.sqrt(-cv_scores['train_neg_mean_squared_error']))\n",
    "    model = cv_scores['estimator'][index]\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, model.predict(X_test)))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_latest_file(mypath=datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stappen hieronder mogelijk verplaatsten naar prepare stap, later beoordelen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# droppen van de rijen waar de y_value leeg is, anders kunnen de modellen er niet mee overweg\n",
    "df.dropna(\n",
    "    axis=0,\n",
    "    how='any',\n",
    "    thresh=None,\n",
    "    subset=Y_VALUE,\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X en y aanmaken\n",
    "X = df.drop(X_DROP_VALUES, axis=1)\n",
    "# y = df[Y_VALUE]*100 # 0.01 -> 1.0 percentage\n",
    "y = df[Y_VALUE] # 0.01 -> 1.0 percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitsen van X en y in train/test. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = TEST_SIZE, random_state = RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitsen van X_train in categorische en numerieke kolommen, om apart te kunnen transformeren\n",
    "cat_cols = X_train.select_dtypes(include=['category']).columns\n",
    "num_cols = X_train.select_dtypes(include=['int64','float64','float32','int32']).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines (pl) maken voor imputing, scaling en OneHotEncoding per datatype \n",
    "\n",
    "# categorie met waarde die is gegeven aan \"MISSING\" toevoegen\n",
    "for col in cat_cols:\n",
    "    # need to add category for missings, otherwise error with OneHotEncoding (volgens mij ook met alleen imputing)\n",
    "    X_train[col].cat.add_categories(NAN_VALUES_CAT_VALUES, inplace=True)\n",
    "categories = [X_train[col].cat.categories for col in cat_cols]\n",
    "\n",
    "# pipeline voor categorial datatype\n",
    "pl_ppc_cat = make_pipeline(\n",
    "     SimpleImputer(\n",
    "         missing_values = np.nan\n",
    "        ,strategy = NAN_VALUES_CAT_STRATEGY\n",
    "        ,fill_value = NAN_VALUES_CAT_VALUES)\n",
    "    ,OneHotEncoder(categories=categories)\n",
    ")\n",
    "\n",
    "# pipeline voor numeriek datatype\n",
    "pl_ppc_num = make_pipeline(\n",
    "      ColumnSelector(cols=COLS_SELECT)\n",
    "    ,SimpleImputer(\n",
    "         missing_values = np.nan\n",
    "        ,strategy = NAN_VALUES_NUM_STRATEGY)\n",
    "    ,StandardScaler()\n",
    "    ,PCA() # PCA heeft behoorlijk wat (positieve) invloed op de scores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines maken om de preprocessing van de imputing te combineren\n",
    "pl_ppc_total = make_column_transformer(\n",
    "     (pl_ppc_cat, cat_cols)\n",
    "    ,(pl_ppc_num, num_cols)\n",
    "    ,remainder = 'drop'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken voor LinearRegression \n",
    "pl_lr = make_pipeline(\n",
    "     pl_ppc_total\n",
    "    ,LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken voor RidgeRegression \n",
    "pl_rr = make_pipeline(\n",
    "     pl_ppc_total\n",
    "    ,Ridge()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken voor Lasso\n",
    "pl_lasso = make_pipeline(\n",
    "      pl_ppc_total\n",
    "     ,Lasso(alpha=0.001)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken voor KNN\n",
    "pl_knn = make_pipeline(\n",
    "      pl_ppc_total\n",
    "     ,KNeighborsRegressor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken voor SVM\n",
    "pl_svm = make_pipeline(\n",
    "      pl_ppc_total\n",
    "     ,SVR()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline maken voor XGB\n",
    "pl_xgb = make_pipeline(\n",
    "      pl_ppc_total\n",
    "     ,XGBRegressor()\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lineair Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores voor LR berekenen\n",
    "lr_scores = cross_validate(\n",
    "    pl_lr, X_train, y_train,\n",
    "    cv = CROSS_VALIDATE,\n",
    "    scoring=([MODEL_SCORING]),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rr_scores = cross_validate(\n",
    "    pl_rr, X_train, y_train,\n",
    "    cv = CROSS_VALIDATE,\n",
    "    scoring = ([MODEL_SCORING]),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_scores = cross_validate(\n",
    "    pl_lasso, X_train, y_train,\n",
    "    cv = CROSS_VALIDATE,\n",
    "    scoring = ([MODEL_SCORING]),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_scores = cross_validate(\n",
    "    pl_knn, X_train, y_train,\n",
    "    cv = CROSS_VALIDATE,\n",
    "    scoring = ([MODEL_SCORING]),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svm_scores = cross_validate(\n",
    "    pl_svm, X_train, y_train,\n",
    "    cv = CROSS_VALIDATE,\n",
    "    scoring = ([MODEL_SCORING]),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_scores = cross_validate(\n",
    "    pl_xgb, X_train, y_train,\n",
    "    cv = CROSS_VALIDATE,\n",
    "    scoring = ([MODEL_SCORING]),\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toevoegen van de beste scores, per model, aan een lijst\n",
    "scores = []\n",
    "scores.append(('Linear Regression',  get_best_model_rmsle(lr_scores)))\n",
    "scores.append(('Ridge Regression',  get_best_model_rmsle(rr_scores)))\n",
    "scores.append(('Lasso', get_best_model_rmsle(lasso_scores)))\n",
    "scores.append(('K Nearest Neighbor', get_best_model_rmsle(knn_scores)))\n",
    "scores.append(('Support Vector Machines', get_best_model_rmsle(svm_scores)))\n",
    "scores.append(('XGBoost', get_best_model_rmsle(xgb_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maken van een dataframe met daarin de gesorteerde scores per model\n",
    "scores = pd.DataFrame(scores)\n",
    "scores.columns = ['Algorithm', 'RMSE'] \n",
    "scores['RMSE'] = scores['RMSE'].map('{:,.10f}'.format)\n",
    "scores = scores.sort_values('RMSE', ascending=True)\n",
    "scores = scores.reset_index(drop=True)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the winner is...\n",
    "print(f\"Het algoritme met de laagste RMSE is:\\n\\n{scores.iloc[0,0]}, met een RMSE van {scores.iloc[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary: select best model (needs function)\n",
    "BEST_SCORE = lasso_scores\n",
    "index = np.argmax(np.sqrt(-BEST_SCORE['train_neg_mean_squared_error']))\n",
    "model = BEST_SCORE['estimator'][index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix_datetime = datetime.strftime(datetime.now(), format='%Y%m%d%H%M')\n",
    "filename = f'../data/best_model_{suffix_datetime}.pickle'\n",
    "\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = get_latest_pickle_file(datapath=datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = loaded_model.score(X_test, y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
