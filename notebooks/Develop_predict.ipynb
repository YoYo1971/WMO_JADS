{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-astronomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# Added (new in developing predict)\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, RepeatedKFold, GridSearchCV, cross_validate, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso, LassoCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "\n",
    "# Custom functions\n",
    "import src.settings as settings\n",
    "import src.mapper_cols as mapper_cols\n",
    "from src.run_all.main_get_data import get_data, get_data_predict\n",
    "from src.run_all.main_preprocess import preprocess_data, preprocess_data_predict\n",
    "from src.utilities.utilities import get_latest_file, list_filenames\n",
    "\n",
    "# instellingen voor panda weergave aanpassen\n",
    "pd.set_option('display.max_rows', 500) # alle rijen tonen\n",
    "pd.set_option('display.max_columns', 500) # alle kolommen tonen\n",
    "pd.set_option('display.width', 1000) # kolombreedte\n",
    "pd.set_option(\"display.precision\", 2)     # precisie van de kolommen aanpassen\n",
    "pd.set_option('display.float_format', lambda x: '{:.15f}'.format(x)) # floats output tot 15 decimalen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspected-nepal",
   "metadata": {},
   "source": [
    "# Load dataframe to extend features for future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data/'\n",
    "filename = 'df_get_data_WMO_WIJK_HUISHOUDENS_BEVOLKING_HEFFING_202104042111.parquet.gzip'\n",
    "df_get_data_WMO = pd.read_parquet(datapath + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fuzzy-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_get_data = df_get_data_WMO.reset_index().copy()\n",
    "df_get_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datapath = '../data/'\n",
    "# filename = 'df_preprocessed_202104042151_Boerenverstand_Maikel.parquet.gzip'\n",
    "# df_preprocessed = pd.read_parquet(datapath + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-niger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(list(df_preprocessed.reset_index().columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-hindu",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "floral-acoustic",
   "metadata": {},
   "source": [
    "# Main_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "periods = [2020,2021,2022]\n",
    "trained_model = get_latest_file(filename_str_contains='best_model_', datapath=datapath, filetype='pickle')\n",
    "df_prognoses = get_data_predict(periods=periods, save_all=True, personal_note=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radical-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_get_data.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get data\n",
    "if df_get_data.empty:\n",
    "    df_get_data_WMO = get_data(save=True)\n",
    "if df_prognoses.empty:\n",
    "    df_prognoses = get_data_predict(periods=periods, save_all=True, personal_note=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocess\n",
    "# Preprocess predict\n",
    "df_preprocessed_predict = preprocess_data_predict(df_get_data, df_prognoses, save_all=True, personal_note=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess (general)\n",
    "df_preprocessed = preprocess_data(df=df_preprocessed_predict, save_all=False, personal_note='predict')\n",
    "df_preprocessed = df_preprocessed.drop(settings.Y_TARGET_COLS, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Predict\n",
    "y_preds = trained_model.predict(df_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-secretary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "partial-spoke",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-disney",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-gibson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-generation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-respect",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acquired-strengthening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-camel",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-valuable",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-preserve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-poster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "brutal-ceremony",
   "metadata": {},
   "source": [
    "## Extend strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import src.settings as settings\n",
    "# from src.preprocess.preprocess import get_and_combine_cbs_tables, rename_and_subset_cols, \\\n",
    "#     get_region_period_spec_val_subtable, downcast_variables_dataframe\n",
    "\n",
    "\n",
    "# pickle file inladen voor predict\n",
    "loaded_model = get_latest_file(filename_str_contains='best_model_', datapath=datapath, filetype='pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-phone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "filename_str_contains='best_model_'\n",
    "datapath='../data/'\n",
    "onlyfiles = sorted([f for f in listdir(datapath) if isfile(join(datapath, f))])\n",
    "# Get last file\n",
    "filename = [s for s in onlyfiles if filename_str_contains in s][-1]\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "favorite-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.run_all.main_predict import predict_data\n",
    "periods = [2020,2021,2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-algebra",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time df = predict_data(df_get_data=df_get_data, periods=periods, trained_model=loaded_model)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_get_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-evening",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-settlement",
   "metadata": {},
   "outputs": [],
   "source": [
    "2235+936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods_2 = [2020,2021,2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "[str(x) for x in periods_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-animal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-planning",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-mumbai",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings.preprocess['MISSING_BOUNDARY'] = 0.99\n",
    "df_preprocessed = preprocess_data(df=df, save_all=False, personal_note='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings.preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-europe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-microphone",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-accuracy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-intensity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-territory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Get data (for extending get data with future)\n",
    "# Determine boundaries for get prognose data\n",
    "roundedto5periods = max(periods) + (5 - max(periods)) % 5\n",
    "total_periods = list(range(min(periods), roundedto5periods+1, 1))\n",
    "\n",
    "print(\"Get 'regio-indeling'\")\n",
    "df_regioindeling = get_and_combine_cbs_tables(dict_tables=settings.predict['DICT_TABLES_REGIOINDELING'],\n",
    "                                              double_trouble_colnames=settings.predict[\n",
    "                                                  'DICT_DOUBLETROUBLECOLNAMES_REGIOINDELING'],\n",
    "                                              url=settings.get_data['CBS_OPEN_URL'])\n",
    "df_regioindeling = rename_and_subset_cols(df=df_regioindeling,\n",
    "                                          dict_rename=settings.predict['DICT_COLS_RENAMED_REGIOINDELING'],\n",
    "                                          list_cols=settings.predict['LIST_COLS_SUBSET_REGIOINDELING'])\n",
    "df_regioindeling[settings.predict['LIST_STR_STRIP_COLS_REGIOINDELING']] = df_regioindeling[\n",
    "    settings.predict['LIST_STR_STRIP_COLS_REGIOINDELING']].apply(lambda x: x.str.strip())\n",
    "\n",
    "print(\"Get 'prognose huishoudens' tables\")\n",
    "df_huishouden_prognose = get_and_combine_cbs_tables(dict_tables=settings.predict['DICT_TABLES_HUISHOUDEN'],\n",
    "                                                    url=settings.get_data['CBS_OPEN_URL'])\n",
    "df_huishouden_prognose['interval'] = df_huishouden_prognose['perioden']\n",
    "df_huishouden_prognose = df_huishouden_prognose.rename(columns=settings.predict['DICT_COLS_RENAMED_HUISHOUDEN'])\n",
    "df_huishouden_prognose = df_huishouden_prognose[df_huishouden_prognose['prognoseinterval'] == 'Prognose']\n",
    "df_huishouden_prognose = df_huishouden_prognose[\n",
    "    (df_huishouden_prognose['gemeentenaam'].str.contains('(CR)') == False) &\n",
    "    (df_huishouden_prognose['gemeentenaam'].str.contains('(PV)') == False) &\n",
    "    (df_huishouden_prognose['gemeentenaam'] != 'Nederland')].copy()\n",
    "df_huishouden_prognose['particulierehuishoudens'] = df_huishouden_prognose['particulierehuishoudens'] * 1000\n",
    "df_huishouden_prognose['particulierehuishoudens'] = df_huishouden_prognose[\n",
    "    'particulierehuishoudens'].round().astype(int)\n",
    "df_huishouden_prognose_pivot = pd.pivot_table(data=df_huishouden_prognose, values='particulierehuishoudens',\n",
    "                                              index=['gemeentenaam', 'interval'],\n",
    "                                              columns=['samenstellingvanhethuishouden'],\n",
    "                                              aggfunc=np.sum).reset_index()\n",
    "df_huishouden_prognose_pivot = df_huishouden_prognose_pivot[\n",
    "    df_huishouden_prognose_pivot['interval'].astype(int) <= roundedto5periods]\n",
    "df_huishouden_prognose_pivot = rename_and_subset_cols(df=df_huishouden_prognose_pivot,\n",
    "                                                      dict_rename=settings.predict[\n",
    "                                                          'DICT_COLS_RENAMED_HUISHOUDEN_PIVOT'],\n",
    "                                                      list_cols=settings.predict[\n",
    "                                                          'LIST_COLS_SUBSET_HUISHOUDING_PIVOT'])\n",
    "\n",
    "print(\"Get 'prognose bevolking' tables\")\n",
    "df_population_prognose = get_and_combine_cbs_tables(dict_tables=settings.predict['DICT_TABLES_BEVOLKING'],\n",
    "                                                    url=settings.get_data['CBS_OPEN_URL'])\n",
    "df_population_prognose = rename_and_subset_cols(df=df_population_prognose,\n",
    "                                                dict_rename=settings.predict['DICT_COLS_RENAMED_BEVOLKING'],\n",
    "                                                list_cols=settings.predict['LIST_COLS_SUBSET_BEVOLKING'])\n",
    "df_population_prognose['interval'] = df_population_prognose['perioden'].apply(lambda x: x.split(' ')[-1])\n",
    "df_population_prognose = df_population_prognose[\n",
    "    (df_population_prognose['gemeentenaam'].str.contains('(CR)') == False) &\n",
    "    (df_population_prognose['gemeentenaam'].str.contains('(PV)') == False) &\n",
    "    (df_population_prognose['gemeentenaam'] != 'Nederland')].copy()\n",
    "df_population_prognose = df_population_prognose[df_population_prognose['interval'].astype(int) <= roundedto5periods]\n",
    "df_population_prognose['aantalinwoners'] = df_population_prognose['aantalinwoners'] * 1000\n",
    "df_population_prognose['aantalinwoners'] = df_population_prognose['aantalinwoners'].round().astype(int)\n",
    "df_population_prognose = df_population_prognose.drop(['perioden'], axis=1)\n",
    "\n",
    "# Merge all dataframes\n",
    "df_prognoses = pd.merge(df_regioindeling, df_huishouden_prognose_pivot, how='left',\n",
    "                        left_on=['gemeentenaam'], right_on=['gemeentenaam'])\n",
    "df_prognoses = pd.merge(df_prognoses, df_population_prognose, how='left',\n",
    "                        left_on=['gemeentenaam', 'interval'],\n",
    "                        right_on=['gemeentenaam', 'interval'])\n",
    "\n",
    "# Concat with original 'get data' dataframe (incl. drop multiplicacities that don't occur in original dataset)\n",
    "list_unchanged_multiplicacities = df_get_data[df_get_data['interval'] == df_get_data['interval'].max()][\n",
    "    'codering_regio'].unique()\n",
    "df_prognoses = df_prognoses[df_prognoses['codering_regio'].isin(list_unchanged_multiplicacities)]\n",
    "df_future = pd.concat([df_get_data, df_prognoses], axis=0)\n",
    "df_future = df_future.sort_values(['codering_regio', 'interval']).reset_index().drop(['index'], axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_cols_prognoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "destroyed-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extend dataframe for blancs\n",
    "# Determine columns for each imputing strategy\n",
    "list_cols_prognoses = df_prognoses.columns\n",
    "# list_cols_prognoses_str = [x for x in list(df_prognoses.loc[:, df_prognoses.dtypes == object].columns) if x!='codering_regio']\n",
    "list_cols_prognoses_num = list(df_prognoses.loc[:, df_prognoses.dtypes != object].columns)\n",
    "list_all_columns = list(df_future.columns)\n",
    "list_cols_str = list(df_future.loc[:, df_future.dtypes == object].columns)\n",
    "list_cols_str = list(set(list_cols_str) - set(list_cols_prognoses))\n",
    "list_cols_trained_model = settings.predict['LIST_COLS_TRAINED_MODEL']\n",
    "list_cols_trained_model = list(set([x.replace('relative_', '') for x in list_cols_trained_model]))\n",
    "list_cols_relate_imputer = list(\n",
    "    set(list_cols_trained_model) - set(settings.predict['LIST_COLS_TRAINED_MODEL_INVARIABLY']) - set(\n",
    "        list_cols_prognoses))\n",
    "list_cols_group_imputer = list(set(list_all_columns)-set(list_cols_str)-set(list_cols_relate_imputer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-thumbnail",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future_cop = df_future.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffill for string columns\n",
    "df_future_cop.loc[:, list_cols_str] = df_future_cop.loc[:, list_cols_str].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utilities.transformers import ColumnSelector, GroupInterpolateImputer, RelativeColumnScaler, \\\n",
    "    CustomScaler, CustomImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group imputer for available future / invariably columns / columns not used in trained model\n",
    "GII = GroupInterpolateImputer(groupcols=settings.predict['GROUP_INTERPOLATE_IMPUTER_GROUPCOLS'],\n",
    "                        interpolate_method=settings.predict['GROUP_INTERPOLATE_IMPUTER_METHOD'],\n",
    "                        cols=list_cols_group_imputer)\n",
    "df_future_cop = GII.fit_transform(df_future_cop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future_cop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-speech",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Relational imputer for other columns in trained model\n",
    "list_cols_relate_imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_col = 'aantalinwoners'\n",
    "future_years = ['2020', '2021', '2022', '2023', '2024', '2025']\n",
    "all_relate_cols_necessary = settings.predict['LIST_COLS_GROUPER_RELATE_IMPUTER']+list_cols_relate_imputer+[base_col]\n",
    "\n",
    "df_base_year = df_future_cop[df_future_cop['interval']=='2019'][all_relate_cols_necessary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_year.loc[:, list_cols_relate_imputer] = df_base_year.loc[:, list_cols_relate_imputer].div(df_base_year['aantalinwoners'], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_year = df_base_year[df_base_year['codering_regio'].isin(df_future_cop[df_future_cop['interval']=='2025'].codering_regio.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-adult",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_base_year.set_index('codering_regio')[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_future_2 = df_future_cop.copy()\n",
    "# df_future_2 = df_future_2.set_index('codering_regio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-hierarchy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_future_2[df_future_2['interval']=='2021'][base_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_future_2[df_future_2['interval']=='2021'].loc[:,col] = df_future_2[df_future_2['interval']=='2021'].loc[:,base_col] * df_base_year.set_index('codering_regio')[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_future_2[df_future_2['interval']=='2021'].loc[:,col]\n",
    "df_future_2[df_future_2['interval']==year].loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future_2[df_future_2['interval']==year].loc[:,base_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base_year.set_index('codering_regio')[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-workstation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future_cop[df_future_cop['interval'].isin(future_years)].loc[:,['codering_regio']+list_cols_relate_imputer+[base_col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-implement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future_2 = df_future_cop.copy()\n",
    "df_future_2 = df_future_2.set_index('codering_regio')\n",
    "for col in list_cols_relate_imputer:\n",
    "    df_future_2.loc[:,col] = df_future_2.loc[:,base_col]\n",
    "    \n",
    "#     for year in future_years:\n",
    "    base_col_series = df_future_2[df_future_2['interval']==year].loc[:,base_col]\n",
    "    perc_col_series = df_base_year.set_index('codering_regio')[col]\n",
    "#         df_future_2[df_future_2['interval']==year].loc[:,col] = base_col_series.multiply(perc_col_series)\n",
    "    df_future_2.loc[:,col] = df_future_2.loc[:,col] * perc_col_series\n",
    "#         print(base_col_series.multiply(perc_col_series))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.507697108383607*9528.333333333333940"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-automation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future_2[~df_future_2['interval'].isin(future_years)].loc[:,list_cols_relate_imputer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "essential-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_future_cop[df_future_cop['interval'].isin(future_years)].loc[:,col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_perc = pd.DataFrame({'code_regio': ['AB01', 'AB02', 'AB03'],\n",
    "                            'interval': ['2019', '2019', '2019'],\n",
    "                            'allenstaande_vrouwen': [0.4, 0.15, 0.2],\n",
    "                            'alleenstaande_mannen': [0.3, 0.1, 0.3]})\n",
    "df_future = pd.DataFrame({'code_regio': ['AB01', 'AB01','AB01','AB02','AB02','AB02', 'AB03','AB03','AB03'],\n",
    "                            'interval': ['2019', '2020', '2021','2019', '2020', '2021', '2019', '2020', '2021'],\n",
    "                            'allenstaande_vrouwen': [4, np.nan, np.nan,15, np.nan, np.nan,5, np.nan, np.nan],\n",
    "                            'alleenstaande_mannen': [3, np.nan, np.nan,11.5, np.nan, np.nan,15, np.nan, np.nan],\n",
    "                            'aantalinwoners': [10,20,30, 100,115,130, 25,50,75]})\n",
    "df_uitkomst = pd.DataFrame({'code_regio': ['AB01', 'AB01','AB01','AB02','AB02','AB02', 'AB03','AB03','AB03'],\n",
    "                            'interval': ['2020', '2021', '2022','2020', '2021', '2022','2020', '2021', '2022'],\n",
    "                            'allenstaande_vrouwen': [4, 8, 12, 15,17.25,19.5, 5,10,15],\n",
    "                            'alleenstaande_mannen': [3,6,9, 10,11.5,13, 7.5,15,22.5],\n",
    "                            'aantalinwoners': [10,20,30, 100,115,130, 25,50,75]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understanding-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uitkomst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-canal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_hist_perc = df_base_year.copy()\n",
    "# df_future = df_future_cop[df_future_cop['interval'].isin(future_years)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uitkomst_test = df_future.copy()\n",
    "df_uitkomst_test = df_uitkomst_test.set_index('code_regio')\n",
    "for col in ['allenstaande_vrouwen', 'alleenstaande_mannen']:\n",
    "# for col in list_cols_relate_imputer:\n",
    "    df_uitkomst_test.loc[:, col] = df_uitkomst_test['aantalinwoners'] * df_hist_perc.set_index('code_regio')[col]\n",
    "#     df_uitkomst_test.loc[:, col] = df_uitkomst_test[base_col] * df_hist_perc.set_index('codering_regio')[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uitkomst_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hist_perc.set_index('code_regio')['alleenstaande_mannen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_prognoses.loc[:, df_prognoses.dtypes == object].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cols_prognoses_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future_cop[df_future_cop['interval'].isin(['2017', '2018', '2019'])][settings.predict['LIST_COLS_GROUPER_RELATE_IMPUTER']+list_cols_prognoses_num+list_cols_relate_imputer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future_cop[df_future_cop['interval'].isin(['2017', '2018', '2019'])][settings.predict['LIST_COLS_GROUPER_RELATE_IMPUTER']+list_cols_prognoses_num+list_cols_relate_imputer].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cols_relate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_past_period = ['2017', '2018', '2019']\n",
    "list_cols_relate = settings.predict['LIST_COLS_GROUPER_RELATE_IMPUTER']+list_cols_relate_imputer\n",
    "df_var = df_future_cop[df_future_cop['interval'].isin(list_past_period)][list_cols_relate+['aantalinwoners']].copy()\n",
    "\n",
    "# for basecol in list_cols_prognoses_num:\n",
    "#     print(basecol)\n",
    "#     df_var.loc[:, list_cols_relate_imputer] = df_var.loc[:, list_cols_relate_imputer] / df_var[basecol]\n",
    "    \n",
    "# df_var.loc[:, list_cols_relate_imputer] = df_var.loc[:, list_cols_relate_imputer].div(df_var['aantalinwoners'], axis=0)\n",
    "# df_var_mean = df_var.groupby(['codering_regio']).mean().drop(['aantalinwoners'], axis=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var['aantalinwoners']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-cartridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var[df_var['codering_regio'].isin(['GM0085', 'GM0017'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future_cop[df_future_cop['codering_regio'].isin(['GM0085', 'GM0017'])][['alleenstaande_mannen', 'alleenstaande_vrouwen', 'aantalinwoners', 'gemeentenaam']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "# statistics.pvariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var.loc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var = df_var.drop(['interval'], axis=1) * 1\n",
    "df_var = df_var.groupby(['codering_regio'])\n",
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb.apply(lambda grp: statistics.pvariance(grp)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_prognoses.loc[:, df_prognoses.dtypes != object].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-cycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future[df_future['interval'].isin(['2017', '2018', '2019'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_future[df_future['interval'].isin(['2020', '2021', '2022', '2023'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifth-copyright",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-heath",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-category",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-journal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-delivery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-impact",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-morgan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-information",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-disney",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-wiring",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumed-battery",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-wonder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-bangladesh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-practitioner",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-scenario",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-default",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-resident",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-strengthening",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.settings as settings\n",
    "from src.preprocess.preprocess import get_and_combine_cbs_tables, rename_and_subset_cols, \\\n",
    "    get_region_period_spec_val_subtable, downcast_variables_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-establishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [2020, 2021, 2022]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "round(max(periods), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-dispute",
   "metadata": {},
   "outputs": [],
   "source": [
    "roundedto5periods = max(periods) + (5 - max(periods)) % 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_periods = list(range(min(periods), roundedto5periods+1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Get 'progonse bevolking' tables\")\n",
    "df_population_prognose = get_and_combine_cbs_tables(dict_tables=settings.predict['DICT_TABLES_BEVOLKING'],\n",
    "                                                    url=settings.get_data['CBS_OPEN_URL'])\n",
    "df_population_prognose = rename_and_subset_cols(df=df_population_prognose,\n",
    "                                                dict_rename=settings.predict['DICT_COLS_RENAMED_BEVOLKING'],\n",
    "                                                list_cols=settings.predict['LIST_COLS_SUBSET_BEVOLKING'])\n",
    "df_population_prognose['interval'] = df_population_prognose['perioden'].apply(lambda x: x.split(' ')[-1])\n",
    "df_population_prognose = df_population_prognose[(df_population_prognose['gemeentenaam'].str.contains('(CR)')==False) & \n",
    "                      (df_population_prognose['gemeentenaam'].str.contains('(PV)')==False) &\n",
    "                      (df_population_prognose['gemeentenaam']!='Nederland')].copy()\n",
    "df_population_prognose = df_population_prognose[df_population_prognose['interval'].astype(int)<=roundedto5periods]\n",
    "df_population_prognose['aantalinwoners'] = df_population_prognose['aantalinwoners'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population_prognose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Get 'prognose huishoudens' tables\")\n",
    "df_huishouden_prognose = get_and_combine_cbs_tables(dict_tables=settings.predict['DICT_TABLES_HUISHOUDEN'],\n",
    "                                                    url=settings.get_data['CBS_OPEN_URL'])\n",
    "df_huishouden_prognose['interval'] = df_huishouden_prognose['perioden']\n",
    "df_huishouden_prognose = df_huishouden_prognose.rename(columns=settings.predict['DICT_COLS_RENAMED_HUISHOUDEN'])\n",
    "df_huishouden_prognose = df_huishouden_prognose[df_huishouden_prognose['prognoseinterval']=='Prognose']\n",
    "df_huishouden_prognose = df_huishouden_prognose[(df_huishouden_prognose['gemeentenaam'].str.contains('(CR)')==False) & \n",
    "                      (df_huishouden_prognose['gemeentenaam'].str.contains('(PV)')==False) &\n",
    "                      (df_huishouden_prognose['gemeentenaam']!='Nederland')].copy()\n",
    "df_huishouden_prognose['particulierehuishoudens'] = df_huishouden_prognose['particulierehuishoudens'].round().astype(int)\n",
    "df_huishouden_prognose_pivot = pd.pivot_table(data=df_huishouden_prognose, values='particulierehuishoudens',\n",
    "                                         index=['gemeentenaam', 'interval'],\n",
    "                                         columns=['samenstellingvanhethuishouden'], aggfunc=np.sum).reset_index()\n",
    "df_huishouden_prognose_pivot = df_huishouden_prognose_pivot[df_huishouden_prognose_pivot['interval'].astype(int) <= roundedto5periods]\n",
    "df_huishouden_prognose_pivot = rename_and_subset_cols(df=df_huishouden_prognose_pivot,\n",
    "                                                dict_rename=settings.predict['DICT_COLS_RENAMED_HUISHOUDEN_PIVOT'],\n",
    "                                                list_cols=settings.predict['LIST_COLS_SUBSET_HUISHOUDING_PIVOT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_huishouden_prognose_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-warner",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Get 'regio-indeling'\")\n",
    "df_regioindeling = get_and_combine_cbs_tables(dict_tables=settings.predict['DICT_TABLES_REGIOINDELING'],\n",
    "                                              double_trouble_colnames=settings.predict[\n",
    "                                                  'DICT_DOUBLETROUBLECOLNAMES_REGIOINDELING'],\n",
    "                                              url=settings.get_data['CBS_OPEN_URL'])\n",
    "df_regioindeling = rename_and_subset_cols(df=df_regioindeling,\n",
    "                                        dict_rename=settings.predict['DICT_COLS_RENAMED_REGIOINDELING'],\n",
    "                                        list_cols=settings.predict['LIST_COLS_SUBSET_REGIOINDELING'])\n",
    "df_regioindeling[settings.predict['LIST_STR_STRIP_COLS_REGIOINDELING']] = df_regioindeling[\n",
    "    settings.predict['LIST_STR_STRIP_COLS_REGIOINDELING']].apply(lambda x: x.str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-index",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regioindeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-exemption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all dataframes\n",
    "\n",
    "df_prognoses = pd.merge(df_regioindeling, df_huishouden_prognose_pivot, how='left', \n",
    "                        left_on=['gemeentenaam'], right_on=['gemeentenaam'])\n",
    "df_prognoses = pd.merge(df_prognoses, df_population_prognose, how='left',\n",
    "                       left_on=['gemeentenaam', 'interval'],\n",
    "                       right_on=['gemeentenaam', 'interval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-headline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "illegal-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prognoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-gates",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-excitement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-pillow",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-works",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbsodata\n",
    "dict_tables=settings.predict['DICT_TABLES_REGIOINDELING']\n",
    "url=settings.get_data['CBS_OPEN_URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of tables to collect: {len(dict_tables)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for interval, table in dict_tables.items():\n",
    "    print(f\"Pythonic iteration {interval} for table {table}\")\n",
    "    df_sub = pd.DataFrame(cbsodata.get_data(table, catalog_url=url))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-kidney",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "{i:i for i in df_sub.columns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "waiting-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'Code_1': 'Code_1gemeente',\n",
    " 'Naam_2': 'Naam_2gemeente',\n",
    " 'SorteringNaam_3': 'SorteringNaam_3gemeente',\n",
    " 'Code_4': 'Code_4arbeidsmarktregio',\n",
    " 'Naam_5': 'Naam_5arbeidsmarktregio',\n",
    " 'Code_6': 'Code_6arrondissementenrechtsgebieden',\n",
    " 'Naam_7': 'Naam_7arrondissementenrechtsgebieden',\n",
    " 'Code_8': 'Code_8corop',\n",
    " 'Naam_9': 'Naam_9corop',\n",
    " 'Code_10': 'Code_10coropsub',\n",
    " 'Naam_11': 'Naam_11coropsub',\n",
    " 'Code_12': 'Code_12coropplus',\n",
    " 'Naam_13': 'Naam_13coropplus',\n",
    " 'Code_14': 'Code_14ggdregio',\n",
    " 'Naam_15': 'Naam_15ggdregio',\n",
    " 'Code_16': 'Code_16jeugdzorgregio',\n",
    " 'Naam_17': 'Naam_17jeugdzorgregio',\n",
    " 'Code_18': 'Code_18kvk',\n",
    " 'Naam_19': 'Naam_19jkvk',\n",
    " 'Code_20': 'Code_20landbouwgebieden',\n",
    " 'Naam_21': 'Naam_21landbouwgebieden',\n",
    " 'Code_22': 'Code_22landbouwgebiedengroepen',\n",
    " 'Naam_23': 'Naam_23landbouwgebiedengroepen',\n",
    " 'Code_24': 'Code_24landsdelen',\n",
    " 'Naam_25': 'Naam_25landsdelen',\n",
    " 'Code_26': 'Code_26nutseen',\n",
    " 'Naam_27': 'Naam_27nutseen',\n",
    " 'Code_28': 'Code_28nutstwee',\n",
    " 'Naam_29': 'Naam_29nutstwee',\n",
    " 'Code_30': 'Code_30nutsdrie',\n",
    " 'Naam_31': 'Naam_31nutsdrie',\n",
    " 'Code_32': 'Code_32provincies',\n",
    " 'Naam_33': 'Naam_33provincies',\n",
    " 'Code_34': 'Code_34regionaleeenheden',\n",
    " 'Naam_35': 'Naam_35regionaleeenheden',\n",
    " 'Code_36': 'Code_36regionaleenergiestrategieregios',\n",
    " 'Naam_37': 'Naam_37regionaleenergiestrategieregios',\n",
    " 'Code_38': 'Code_38regionalemeldencoordinatiepunten',\n",
    " 'Naam_39': 'Naam_39regionalemeldencoordinatiepunten',\n",
    " 'Code_40': 'Code_40regioplusarbeidsmarktregios',\n",
    " 'Naam_41': 'Naam_41regioplusarbeidsmarktregios',\n",
    " 'Code_42': 'Code_42ressortenrechtsgebieden',\n",
    " 'Naam_43': 'Naam_43ressortenrechtsgebieden',\n",
    " 'Code_44': 'Code_44subresregios',\n",
    " 'Naam_45': 'Naam_45subresregios',\n",
    " 'Code_46': 'Code_46toeristengebieden',\n",
    " 'Naam_47': 'Naam_47toeristengebieden',\n",
    " 'Code_48': 'Code_48veiligheidsregios',\n",
    " 'Naam_49': 'Naam_49veiligheidsregios',\n",
    " 'Code_50': 'Code_50zorgkantoorregios',\n",
    " 'Naam_51': 'Naam_51zorgkantoorregios',\n",
    " 'Code_52': 'Code_52gemeentegrootte',\n",
    " 'Omschrijving_53': 'Omschrijving_53gemeentegrootte',\n",
    " 'Code_54': 'Code_54stedelijksheidsklase',\n",
    " 'Omschrijving_55': 'Omschrijving_55stedelijkheidsklasse',\n",
    " 'Inwonertal_56': 'Inwonertal_56',\n",
    " 'Omgevingsadressendichtheid_57': 'Omgevingsadressendichtheid_57'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-skill",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'ID', 'RegioS', \n",
    " 'Code_1':'codegemeente', \n",
    " 'Naam_2':'naamgemeente', \n",
    " 'SorteringNaam_3': , 'Code_4', 'Naam_5', 'Code_6', 'Naam_7', 'Code_8', 'Naam_9', 'Code_10', 'Naam_11', 'Code_12', 'Naam_13', 'Code_14', 'Naam_15', 'Code_16', 'Naam_17', 'Code_18', 'Naam_19', 'Code_20', 'Naam_21', 'Code_22', 'Naam_23', 'Code_24', 'Naam_25', 'Code_26', 'Naam_27', 'Code_28', 'Naam_29', 'Code_30', 'Naam_31', 'Code_32', 'Naam_33', 'Code_34', 'Naam_35', 'Code_36', 'Naam_37', 'Code_38', 'Naam_39', 'Code_40', 'Naam_41', 'Code_42', 'Naam_43', 'Code_44', 'Naam_45', 'Code_46', 'Naam_47', 'Code_48', 'Naam_49', 'Code_50', 'Naam_51', 'Code_52', 'Omschrijving_53', 'Code_54', 'Omschrijving_55', 'Inwonertal_56', 'Omgevingsadressendichtheid_57'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of tables to collect: {len(dict_tables)}\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for interval, table in dict_tables.items():\n",
    "    print(f\"Pythonic iteration {interval} for table {table}\")\n",
    "    try:\n",
    "        df_sub = pd.DataFrame(cbsodata.get_data(table, catalog_url=url))\n",
    "        if double_trouble_colnames:\n",
    "            df_sub = df_sub.rename(columns=double_trouble_colnames)\n",
    "        cols_wijk_stripped = [i.rstrip('0123456789').replace(\"_\", \"\").lower() for i in list(df_sub.columns)]\n",
    "        dict_wijk_cols_renamed = {key: value for key, value in zip(iter(df_sub.columns), iter(cols_wijk_stripped))}\n",
    "        df_sub = df_sub.rename(columns=dict_wijk_cols_renamed)\n",
    "        df_sub['interval'] = interval\n",
    "        # print(list(df_sub.columns))\n",
    "    except Exception:\n",
    "        df_sub = pd.DataFrame()\n",
    "        pass\n",
    "    df = pd.concat([df, df_sub], sort=True)\n",
    "    # print(list(df.columns))\n",
    "return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-senator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-optimization",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-relay",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-heading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_huishouden_prognose_pivot = pd.pivot_table(data=df_huishouden_prognose, values='particulierehuishoudens',\n",
    "                                         index=['regioindeling', 'interval'],\n",
    "                                         columns=['samenstellingvanhethuishouden'], aggfunc=np.sum).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-intensity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_huishouden_prognose_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-ordinance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-casting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_huishouden_prognose = df_huishouden_prognose[(df_huishouden_prognose['regioindeling'].str.contains('(CR)')==False) & \n",
    "                      (df_huishouden_prognose['regioindeling'].str.contains('(PV)')==False) &\n",
    "                      (df_huishouden_prognose['regioindeling']!='Nederland')].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"col1\"].str.contains('this'|'that')==False and df[\"col2\"].str.contains('foo'|'bar')==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population_prognose = rename_and_subset_cols(df=df_population_prognose,\n",
    "                                    dict_rename=settings.get_data['DICT_COLS_RENAMED_WMO'],\n",
    "                                    list_cols=settings.get_data['LIST_COLS_SUBSET_WMO'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population_prognose['interval'] = df_population_prognose['perioden'].apply(lambda x: x.split(' ')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-teens",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-maldives",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pending-washington",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-cannon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-underground",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-applicant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-pricing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "developmental-alpha",
   "metadata": {},
   "source": [
    "# Extend dataframe with future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-local",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_unique_regions = list(df[df['interval']==df['interval'].max()]['codering_regio'].unique())\n",
    "list_future_years = ['2020', '2021', '2022']\n",
    "df_future = pd.DataFrame(list(product(list_unique_regions, list_future_years)), columns=['codering_regio', 'interval'])\n",
    "df_extended = pd.concat([df, df_future])\n",
    "df_extended['interval'] = df_extended['interval'].astype(int)\n",
    "df_extended = df_extended.sort_values(['codering_regio', 'interval']).reset_index().drop(['index'], axis=1)\n",
    "df_extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-conversation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "friendly-insulin",
   "metadata": {},
   "source": [
    "# Strategy one: Use GroupInterpolateImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "difficult-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import src.settings as settings\n",
    "from src.preprocess.preprocess import make_df_missing\n",
    "from src.utilities.transformers import ColumnSelector, GroupInterpolateImputer, RelativeColumnScaler, \\\n",
    "    CustomScaler, CustomImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocess = df_extended.reset_index().copy()\n",
    "# Determine columns with to much missing values\n",
    "df_missing = make_df_missing(df_preprocess)\n",
    "list_drop_missing_cols = list(\n",
    "    df_missing[df_missing['perc_missing'] > 0.99].index)\n",
    "\n",
    "# Determine columns which are not numeric but objects\n",
    "list_drop_object_cols = list(df_preprocess.loc[:, df_preprocess.dtypes == object].columns)\n",
    "\n",
    "# Determine list of columns for first ColumnSelector\n",
    "drop_cols_total = list(set(list_drop_missing_cols + list_drop_object_cols))\n",
    "drop_cols_total = [c for c in drop_cols_total if c not in settings.preprocess['ORIGINAL_INDEX']]\n",
    "list_column_selector_1 = [c for c in list(df_preprocess.columns) if c not in drop_cols_total]\n",
    "\n",
    "# Make Pipeline and fit transform df_preprocess\n",
    "pl_preprocess = make_pipeline(\n",
    "    ColumnSelector(cols=list_column_selector_1),\n",
    "    GroupInterpolateImputer(groupcols=settings.preprocess['GROUP_INTERPOLATE_IMPUTER_GROUPCOLS'],\n",
    "                            interpolate_method='values',\n",
    "                            cols=settings.preprocess['GROUP_INTERPOLATE_IMPUTER_COLS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed = pl_preprocess.fit_transform(df_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-conference",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed[df_preprocessed['codering_regio']=='GM0197']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create sample set for developing visualisation\n",
    "# df_test_set_for_visualise = df_preprocessed[['codering_regio', 'interval', 'wmoclientenper1000inwoners']].copy()\n",
    "\n",
    "# mu, sigma = 0, 0.1 \n",
    "# noise = np.random.normal(mu, sigma, len(df_test_set_for_visualise)) \n",
    "\n",
    "# df_test_set_for_visualise['wmoclientenper1000inwoners'] = df_test_set_for_visualise['wmoclientenper1000inwoners'] + noise\n",
    "# df_test_set_for_visualise.to_csv('../data/sampleset_y_predict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.interpolate.__code__.co_varnames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-violin",
   "metadata": {},
   "source": [
    "# Strategy 2: ffill + percentage\n",
    "Including making method to determine percentage:\n",
    "   \n",
    "* Population growth percentage per type of region? Whole country?\n",
    "* Fixed?\n",
    "* Certain age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-bobby",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-belgium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "numerical-surgery",
   "metadata": {},
   "source": [
    "# Strategy 3: Prognose CBS\n",
    "\n",
    "Mogelijke tabellen: \n",
    "* 84525NED -> niet alle gemeenten\n",
    "* 84528NED -> Slechts per 5 jaar\n",
    "* 84526NED -> huishoudens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cbsodata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-milan",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = '84526NED'\n",
    "url = settings.get_data['CBS_OPEN_URL']\n",
    "df_prognose_bevolking = pd.DataFrame(cbsodata.get_data(table, catalog_url=url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-lodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = '84528NED'\n",
    "url = settings.get_data['CBS_OPEN_URL']\n",
    "df_prognose_bevolking2 = pd.DataFrame(cbsodata.get_data(table, catalog_url=url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prognose_bevolking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prognose_bevolking2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prognose_bevolking.SamenstellingVanHetHuishouden.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prognose_bevolking.RegioIndeling2018.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-savage",
   "metadata": {},
   "source": [
    "# Load model, select columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-knowing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-pressure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data(df_get_data, periods, trained_model, save_all=False, personal_note=\"\"):\n",
    "\n",
    "\n",
    "    ## Get data (for extending get data with future)\n",
    "    # Determine boundaries for get prognose data\n",
    "    roundedto5periods = max(periods) + (5 - max(periods)) % 5\n",
    "    total_periods = list(range(min(periods), roundedto5periods+1, 1))\n",
    "    total_periods_str = [str(x) for x in total_periods]\n",
    "\n",
    "    print(\"Get 'regio-indeling'\")\n",
    "    df_regioindeling = get_and_combine_cbs_tables(dict_tables=settings.predict['DICT_TABLES_REGIOINDELING'],\n",
    "                                                  double_trouble_colnames=settings.predict[\n",
    "                                                      'DICT_DOUBLETROUBLECOLNAMES_REGIOINDELING'],\n",
    "                                                  url=settings.get_data['CBS_OPEN_URL'])\n",
    "    df_regioindeling = rename_and_subset_cols(df=df_regioindeling,\n",
    "                                              dict_rename=settings.predict['DICT_COLS_RENAMED_REGIOINDELING'],\n",
    "                                              list_cols=settings.predict['LIST_COLS_SUBSET_REGIOINDELING'])\n",
    "    df_regioindeling[settings.predict['LIST_STR_STRIP_COLS_REGIOINDELING']] = df_regioindeling[\n",
    "        settings.predict['LIST_STR_STRIP_COLS_REGIOINDELING']].apply(lambda x: x.str.strip())\n",
    "\n",
    "    print(\"Get 'prognose huishoudens' tables\")\n",
    "    df_huishouden_prognose = get_and_combine_cbs_tables(dict_tables=settings.predict['DICT_TABLES_HUISHOUDEN'],\n",
    "                                                        url=settings.get_data['CBS_OPEN_URL'])\n",
    "    df_huishouden_prognose['interval'] = df_huishouden_prognose['perioden']\n",
    "    df_huishouden_prognose = df_huishouden_prognose.rename(columns=settings.predict['DICT_COLS_RENAMED_HUISHOUDEN'])\n",
    "    df_huishouden_prognose = df_huishouden_prognose[df_huishouden_prognose['prognoseinterval'] == 'Prognose']\n",
    "    df_huishouden_prognose = df_huishouden_prognose[\n",
    "        (df_huishouden_prognose['gemeentenaam'].str.contains('(CR)') == False) &\n",
    "        (df_huishouden_prognose['gemeentenaam'].str.contains('(PV)') == False) &\n",
    "        (df_huishouden_prognose['gemeentenaam'] != 'Nederland')].copy()\n",
    "    df_huishouden_prognose['particulierehuishoudens'] = df_huishouden_prognose['particulierehuishoudens'] * 1000\n",
    "    df_huishouden_prognose['particulierehuishoudens'] = df_huishouden_prognose[\n",
    "        'particulierehuishoudens'].round().astype(int)\n",
    "    df_huishouden_prognose_pivot = pd.pivot_table(data=df_huishouden_prognose, values='particulierehuishoudens',\n",
    "                                                  index=['gemeentenaam', 'interval'],\n",
    "                                                  columns=['samenstellingvanhethuishouden'],\n",
    "                                                  aggfunc=np.sum).reset_index()\n",
    "    df_huishouden_prognose_pivot = df_huishouden_prognose_pivot[\n",
    "        df_huishouden_prognose_pivot['interval'].astype(int) <= roundedto5periods]\n",
    "    df_huishouden_prognose_pivot = rename_and_subset_cols(df=df_huishouden_prognose_pivot,\n",
    "                                                          dict_rename=settings.predict[\n",
    "                                                              'DICT_COLS_RENAMED_HUISHOUDEN_PIVOT'],\n",
    "                                                          list_cols=settings.predict[\n",
    "                                                              'LIST_COLS_SUBSET_HUISHOUDING_PIVOT'])\n",
    "\n",
    "    print(\"Get 'prognose bevolking' tables\")\n",
    "    df_population_prognose = get_and_combine_cbs_tables(dict_tables=settings.predict['DICT_TABLES_BEVOLKING'],\n",
    "                                                        url=settings.get_data['CBS_OPEN_URL'])\n",
    "    df_population_prognose = rename_and_subset_cols(df=df_population_prognose,\n",
    "                                                    dict_rename=settings.predict['DICT_COLS_RENAMED_BEVOLKING'],\n",
    "                                                    list_cols=settings.predict['LIST_COLS_SUBSET_BEVOLKING'])\n",
    "    df_population_prognose['interval'] = df_population_prognose['perioden'].apply(lambda x: x.split(' ')[-1])\n",
    "    df_population_prognose = df_population_prognose[\n",
    "        (df_population_prognose['gemeentenaam'].str.contains('(CR)') == False) &\n",
    "        (df_population_prognose['gemeentenaam'].str.contains('(PV)') == False) &\n",
    "        (df_population_prognose['gemeentenaam'] != 'Nederland')].copy()\n",
    "    df_population_prognose = df_population_prognose[df_population_prognose['interval'].astype(int) <= roundedto5periods]\n",
    "    df_population_prognose['aantalinwoners'] = df_population_prognose['aantalinwoners'] * 1000\n",
    "    df_population_prognose['aantalinwoners'] = df_population_prognose['aantalinwoners'].round().astype(int)\n",
    "    df_population_prognose = df_population_prognose.drop(['perioden'], axis=1)\n",
    "\n",
    "    # Merge all dataframes\n",
    "    df_prognoses = pd.merge(df_regioindeling, df_huishouden_prognose_pivot, how='left',\n",
    "                            left_on=['gemeentenaam'], right_on=['gemeentenaam'])\n",
    "    df_prognoses = pd.merge(df_prognoses, df_population_prognose, how='left',\n",
    "                            left_on=['gemeentenaam', 'interval'],\n",
    "                            right_on=['gemeentenaam', 'interval'])\n",
    "    print(f\"Shape of df_prognoses = {df_prognoses.shape}\")\n",
    "\n",
    "    # Concat with original 'get data' dataframe (incl. drop multiplicacities that don't occur in original dataset)\n",
    "    list_unchanged_multiplicacities = df_get_data[df_get_data['interval'] == df_get_data['interval'].max()][\n",
    "        'codering_regio'].unique()\n",
    "    df_prognoses = df_prognoses[df_prognoses['codering_regio'].isin(list_unchanged_multiplicacities)]\n",
    "    print(f\"Shape of df_prognoses = {df_prognoses.shape}\")\n",
    "    df_future = pd.concat([df_get_data, df_prognoses], axis=0)\n",
    "    df_future = df_future.sort_values(['codering_regio', 'interval']).reset_index().drop(['index'], axis=1)\n",
    "    print(f\"Shape of df_future = {df_future.shape}\")\n",
    "\n",
    "    ## Extend dataframe for blancs\n",
    "    print(\"Start extending blancs in DataFrame with future values\")\n",
    "    # Determine columns for each imputing strategy\n",
    "    list_cols_prognoses = df_prognoses.columns\n",
    "    # list_cols_prognoses_str = [x for x in list(df_prognoses.loc[:, df_prognoses.dtypes == object].columns) if x!='codering_regio']\n",
    "    list_cols_prognoses_num = list(df_prognoses.loc[:, df_prognoses.dtypes != object].columns)\n",
    "    list_all_columns = list(df_future.columns)\n",
    "    list_cols_str = list(df_future.loc[:, df_future.dtypes == object].columns)\n",
    "    list_cols_str = list(set(list_cols_str) - set(list_cols_prognoses))\n",
    "    list_cols_trained_model = settings.predict['LIST_COLS_TRAINED_MODEL']\n",
    "    list_cols_trained_model = list(set([x.replace('relative_', '') for x in list_cols_trained_model]))\n",
    "    list_cols_relate_imputer = list(\n",
    "        set(list_cols_trained_model) - set(settings.predict['LIST_COLS_TRAINED_MODEL_INVARIABLY']) - set(\n",
    "            list_cols_prognoses))\n",
    "    list_cols_group_imputer = list(set(list_all_columns) - set(list_cols_str) - set(list_cols_relate_imputer))\n",
    "\n",
    "    # ffill for string columns\n",
    "    print(\"ffill for string columns\")\n",
    "    df_future.loc[:, list_cols_str] = df_future.loc[:, list_cols_str].ffill()\n",
    "    print(f\"Shape of df_future = {df_future.shape}\")\n",
    "\n",
    "    # Group imputer for available future / invariably columns / columns not used in trained model\n",
    "    print(\"Group imputer for available future / invariably columns / columns not used in trained model\")\n",
    "    GII = GroupInterpolateImputer(groupcols=settings.predict['GROUP_INTERPOLATE_IMPUTER_GROUPCOLS'],\n",
    "                                  interpolate_method=settings.predict['GROUP_INTERPOLATE_IMPUTER_METHOD'],\n",
    "                                  cols=list_cols_group_imputer)\n",
    "    df_future = GII.fit_transform(df_future)\n",
    "    print(f\"Shape of df_future = {df_future.shape}\")\n",
    "\n",
    "    # Relational imputer for other columns in trained model\n",
    "    print(\"Relational imputer for other columns in trained model\")\n",
    "    base_col = 'aantalinwoners'\n",
    "    # future_years = ['2020', '2021', '2022', '2023', '2024', '2025']\n",
    "    all_relate_cols_necessary = settings.predict['LIST_COLS_GROUPER_RELATE_IMPUTER'] + list_cols_relate_imputer + [\n",
    "        base_col]\n",
    "    df_base_year = df_future[df_future['interval'] == '2019'][all_relate_cols_necessary]\n",
    "    df_base_year.loc[:, list_cols_relate_imputer] = df_base_year.loc[:, list_cols_relate_imputer].div(\n",
    "        df_base_year[base_col], axis=0)\n",
    "    df_base_year = df_base_year[df_base_year['codering_regio'].isin(\n",
    "        df_future[df_future['interval'] == total_periods[-1]].codering_regio.unique())]\n",
    "    df_future = df_future.set_index('codering_regio')\n",
    "    for col in list_cols_relate_imputer:\n",
    "        df_future.loc[:, col] = df_future.loc[:, base_col]\n",
    "        df_future.loc[:, col] = df_future.loc[:, col] * df_base_year.set_index('codering_regio')[col]\n",
    "    print(f\"Shape of df_future = {df_future.shape}\")\n",
    "    df_future = df_future[df_future['interval'].isin(total_periods_str)].reset_index()\n",
    "    df_future = df_future.set_index(['codering_regio', 'interval'])\n",
    "    print(f\"Shape of df_future = {df_future.shape}\")\n",
    "\n",
    "    ## Preprocess\n",
    "    df_preprocessed = preprocess_data(df=df_future, save_all=False, personal_note='predict')\n",
    "    df_preprocessed = df_preprocessed.drop(settings.Y_TARGET_COLS, axis=1)\n",
    "\n",
    "    ## Predict\n",
    "    y_preds = trained_model.predict(df_preprocessed)\n",
    "\n",
    "    # Save\n",
    "    # ?\n",
    "    return y_preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:jads-env] *",
   "language": "python",
   "name": "conda-env-jads-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
